{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8f631755",
      "metadata": {
        "id": "8f631755"
      },
      "source": [
        "# Openreview analysis\n",
        "This notebook demonstrates and explains how to extract meaningful insights from the OpenReview dataset. The objective is to understand how we can learn from previous paper submissions in order to identify patterns that contribute to writing more successful (i.e., accepted) papers.\n",
        "\n",
        "### Authors\n",
        "Dorijan Di Zepp - dorijan.dizepp@studenti.unitn.it"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6NWuhtxmIJJ",
      "metadata": {
        "id": "b6NWuhtxmIJJ"
      },
      "source": [
        "# Dataset analysis\n",
        "\n",
        "The first step, before applying any machine learning models, is to explore and understand the structure of the dataset. This helps us identify which fields are the most informative for our analysis and which ones can be safely ignored. By doing so, we gain a better view of the available data and also improve the efficiency of our computations by filtering out irrelevant or redundant information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb11cea0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cb11cea0",
        "outputId": "e5c4539d-26cd-4e2f-a989-e7f2fba71d27"
      },
      "outputs": [],
      "source": [
        "%pip install pandas\n",
        "%pip install openpyxl\n",
        "%pip install matplotlib\n",
        "%pip install seaborn\n",
        "%pip install torch\n",
        "%pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f240df37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "id": "f240df37",
        "outputId": "f7eabedd-ac15-4927-f990-aef9f59d5935"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7766, 19)\n",
            "Index(['title', 'publish_time', 'abstract', 'keyword', 'tL_DL', 'titlelength',\n",
            "       'paper_decision_time', 'paper_decision', 'paper_decision_comment',\n",
            "       'paper_decision_commentlength', 'review_publish_time', 'reviewer_level',\n",
            "       'paper_score', 'rate', 'review_score_one', 'review_score_two',\n",
            "       'review_score_three', 'review', 'review_contentlength'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 7766,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2558,\n        \"samples\": [\n          \"Emergent Tool Use From Multi-Agent Autocurricula | OpenReview\",\n          \"Searching to Exploit Memorization Effect in Learning from Corrupted Labels | OpenReview\",\n          \"The asymptotic spectrum of the Hessian of DNN throughout training | OpenReview\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"publish_time\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"26 Sep 2019 (modified: 28 Nov 2019)\",\n          \"26 Sep 2019 (modified: 07 Dec 2019)\",\n          \"26 Sep 2019 (modified: 20 Dec 2019)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2558,\n        \"samples\": [\n          \"Abstract:###Through multi-agent competition, the simple objective of hide-and-seek, and standard reinforcement learning algorithms at scale, we find that agents create a self-supervised autocurriculum inducing multiple distinct rounds of emergent strategy, many of which require sophisticated tool use and coordination. We find clear evidence of six emergent phases in agent strategy in our environment, each of which creates a new pressure for the opposing team to adapt; for instance, agents learn to build multi-object shelters using moveable boxes which in turn leads to agents discovering that they can overcome obstacles using ramps. We further provide evidence that multi-agent competition may scale better with increasing environment complexity and leads to behavior that centers around far more human-relevant skills than other self-supervised reinforcement learning methods such as intrinsic motivation. Finally, we propose transfer and fine-tuning as a way to quantitatively evaluate targeted capabilities, and we compare hide-and-seek agents to both intrinsic motivation and random initialization baselines in a suite of domain-specific intelligence tests.\",\n          \"Abstract:###Sample-selection approaches, which attempt to pick up clean instances from the training data set, have become one promising direction to robust learning from corrupted labels. These methods all build on the memorization effect, which means deep networks learn easy patterns first and then gradually over-fit the training data set. In this paper, we show how to properly select instances so that the training process can benefit the most from the memorization effect is a hard problem. Specifically, memorization can heavily depend on many factors, e.g., data set and network architecture. Nonetheless, there still exists general patterns of how memorization can occur. These facts motivate us to exploit memorization by automated machine learning (AutoML) techniques. First, we designed an expressive but compact search space based on observed general patterns. Then, we propose to use the natural gradient-based search algorithm to efficiently search through space. Finally, extensive experiments on both synthetic data sets and benchmark data sets demonstrate that the proposed method can not only be much efficient than existing AutoML algorithms but can also achieve much better performance than the state-of-the-art approaches for learning from corrupted labels.\",\n          \"Abstract:###The dynamics of DNNs during gradient descent is described by the so-called Neural Tangent Kernel (NTK). In this article, we show that the NTK allows one to gain precise insight into the Hessian of the cost of DNNs: we obtain a full characterization of the asymptotics of the spectrum of the Hessian, at initialization and during training.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keyword\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2269,\n        \"samples\": [\n          \"Keywords:###audio adversarial examples, attack, machine learning\",\n          \"Keywords:###multi-task learning, attention mechanism\",\n          \"Keywords:###GANs, Generative Models, Density Estimation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tL_DL\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1910,\n        \"samples\": [\n          \"TL;DR:###On using BERT as an encoder for sequential prediction of labels in multi-label text classification task\",\n          \"TL;DR:###Accelerating CNN training on a Pipeline of Accelerators with Stale Weights\",\n          \"TL;DR:###Keras for infinite neural networks.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"titlelength\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 23,\n        \"max\": 162,\n        \"num_unique_values\": 123,\n        \"samples\": [\n          50,\n          93,\n          71\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_decision_time\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 43,\n        \"samples\": [\n          \"2019-11-22 00:00:00\",\n          \"14 Nov 2019 (modified: 14 Nov 2019)\",\n          \"2019-11-12 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_decision\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Decision:###Accept (Poster)\",\n          \"Decision:###Accept (Talk)\",\n          \"Decision:###Reject\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_decision_comment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2200,\n        \"samples\": [\n          \"Comment:###This paper examines how different distributions of the layer-wise number of CNN filters, as partitioned into a set of fixed templates, impacts the performance of various baseline deep architectures. Testing is conducting from the viewpoint of balancing accuracy with various resource metrics such as number of parameters, memory footprint, etc. In the end, reviewer scores were partitioned as two accepts and two rejects. However, the actual comments indicate that both nominal accept reviewers expressed borderline opinions regarding this work (e.g., one preferred a score of 4 or 5 if available, while the other explicitly stated that the paper was borderline acceptance-worthy). Consequently in aggregate there was no strong support for acceptance and non-dismissable sentiment towards rejection. For example, consistent with reviewer comments, a primary concern with this paper is that the novelty and technical contribution is rather limited, and hence, to warrant acceptance the empirical component should be especially compelling. However, all the experiments are limited to cifar10/cifar100 data, with the exception of a couple extra tests on tiny ImageNet added after the rebuttal. But these latter experiments are not so convincing since the base architecture has the best accuracy on VGG, and only on a single MobileNet test do we actually see clear-cut improvement. Moreover, these new results appear to be based on just a single trial per data set (this important detail is unclear), and judging from Figure 2 of the revision, MobileNet results on cifar data can have very high variance blurring the distinction between methods. It is therefore hard to draw firm conclusions at this point, and these two additional tiny ImageNet tests notwithstanding, we don*t really know how to differentiate phenomena that are intrinsic to cifar data from other potentially relevant factors. Overall then, my view is that far more testing with different data types is warranted to strengthen the conclusions of this paper and compensate for the modest technical contribution. Note also that training with all of these different filter templates is likely no less computationally expensive than some state-of-the-art pruning or related compression methods, and therefore it would be worth comparing head-to-head with such approaches. This is especially true given that in many scenarios, test-time computational resources are more critical than marginal differences in training time, etc.\",\n          \"Comment:###Main content: Blind review #3 summarizes it well: This paper presents a technique for encoding the high level \\u201cstyle\\u201d of pieces of symbolic music. The music is represented as a variant of the MIDI format. The main strategy is to condition a Music Transformer architecture on this global \\u201cstyle embedding\\u201d. Additionally, the Music Transformer model is also conditioned on a combination of both \\u201cstyle\\u201d and \\u201cmelody\\u201d embeddings to try and generate music \\u201csimilar\\u201d to the conditioning melody but in the style of the performance embedding. -- Discussion: The reviewers questioned the novelty. Blind review #2 wrote: *Overall, I think the paper presents an interesting application and parts of it are well written, however I have concerns with the technical presentation in parts of the paper and some of the methodology. Firstly, I think the algorithmic novelty in the paper is fairly limited. The performance conditioning vector is generated by an additional encoding transformer, compared to the Music Transformer paper (Huang et. al. 2019b). However, the limited algorithmic novelty is not the main concern. The authors also mention an internal dataset of music audio and transcriptions, which can be a major contribution to the music information retrieval (MIR) community. However it is not clear if this dataset will be publicly released or is only for internal experiments.* However, after revision, the same reviewer has upgraded the review to a weak accept, as the authors wrote *We emphasize that our goal is to provide users with more fine-grained control over the outputs generated by a seq2seq language model. Despite its simplicity, our method is able to learn a global representation of style for a Transformer, which to the best of our knowledge is a novel contribution for music generation. Additionally, we can synthesize an arbitrary melody into the style of another performance, and we demonstrate the effectiveness of our results both quantitatively (metrics) and qualitatively (interpolations, samples, and user listening studies).* -- Recommendation and justification: This paper is borderline for the reasons above, and due to the large number of strong papers, is not accepted at this time. As one comment, this work might actually be more suitable for a more specialized conference like ISMIR, as its novel contribution is more to music applications than to fundamental machine learning approaches.\",\n          \"Comment:###This work extends the previously introduced NMN for VQA for handling reasoning over text using symbolic reasoning components that can perform counting, sorting etc and can be compositionally combined. Moreover, to successfully train the model, the authors introduce a simple unsupervised auxiliary loss for training the IE components as well heuristically incorporating inductive biases in the behaviour on couple of components. All reviews agreed that this is a challenging topic and an interesting approach to symbolic reasoning over text. At the same time, reviewers did point that experiments are borderline thin, since the authors start with DROP and drop questions that are not particularly suited for symbolic reasoning, resulting in a substantially smaller dataset. Despite the fact that the experiments could probably be stronger, I\\u2019m recommending acceptance cause this topic is very interesting and this is a good paper to raise discussions at ICLR,\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_decision_commentlength\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 543,\n        \"min\": 0,\n        \"max\": 4794,\n        \"num_unique_values\": 1142,\n        \"samples\": [\n          558,\n          735,\n          1084\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_publish_time\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3128,\n        \"samples\": [\n          \"04 Nov 2019 (modified: 21 Nov 2019) 12 Nov 2019 (modified: 16 Nov 2019) 16 Nov 2019\",\n          \"27 Oct 2019 (modified: 06 Nov 2019) 14 Nov 2019 (modified: 15 Nov 2019)\",\n          \"22 Oct 2019 (modified: 23 Nov 2019) 12 Nov 2019 (modified: 12 Nov 2019) 14 Nov 2019 16 Nov 2019\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reviewer_level\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Experience Assessment:###I have read many papers in this area.\",\n          \"Experience Assessment:###I have published one or two papers in this area.\",\n          \"Experience Assessment:###I have published in this field for several years.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_score\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Rating:###6: Weak Accept\",\n          \"Rating:###1: Reject\",\n          \"Rating:###3: Weak Reject\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0073147360967964,\n        \"min\": 1.0,\n        \"max\": 8.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          6.0,\n          1.0,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_score_one\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Review Assessment: Thoroughness In Paper Reading:###I read the paper thoroughly.\",\n          \"Review Assessment: Thoroughness In Paper Reading:###N/A\",\n          \"Review Assessment: Thoroughness In Paper Reading:###I read the paper at least twice and used my best judgement in assessing the paper.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_score_two\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Review Assessment: Checking Correctness Of Experiments:###I assessed the sensibility of the experiments.\",\n          \"Review Assessment: Checking Correctness Of Experiments:###I did not assess the experiments.\",\n          \"Review Assessment: Checking Correctness Of Experiments:###I carefully checked the experiments.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_score_three\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Review Assessment: Checking Correctness Of Derivations And Theory:###I carefully checked the derivations and theory.\",\n          \"Review Assessment: Checking Correctness Of Derivations And Theory:###N/A\",\n          \"Review Assessment: Checking Correctness Of Derivations And Theory:###I assessed the sensibility of the derivations and theory.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7765,\n        \"samples\": [\n          \"Review:###This paper studies the so called problem of derivative-free optimization, which is relevant for cases when the evaluation function is continuous but access to gradients is not possible. The paper improves on top of the stochastic three points method (STP), an existing work (published in arXiv), by proposing adding momentum (SMTP). The intuition behind both STP and SMTP is rather straighforward: you sample a random direction s, then given your current position x you check x+as and x-as. You then move to the best position from (x, x+as, x_as). In a way, this is like computing the numerical derivatives (instead of the gradient) given a random location and its mirror, and then applying gradient descent given the best numerical derivative. However, take this analogy with a large grain of salt, as there are many differences with GD. The proposed algorithm adds momentum and importance sampling. Momentum helps speed up convergence, as the paper shows for non-convex, convex and strongly convex functions. All three cases are individually examined and bounds are derived regarding the speed of convergence. For the non-convex case the speed of convergence is 1/sqrt{K}, K being the number of iterations. For the convex case it is 1/K. For the strongly convex case the (unrealistic) assumption of knowing the optimal value is removed while maintaining the same speed of convergence. Importance sampling helps computing the derivatives focusing on those coordinate dimensions that are more critical to the objective function f(x), improving the speed of convergence further. The importance sampling is proportional to the coordinate-wise Lipschitz constants, assuming that the objective function is coordinate-wise Lipschitz smooth. The methods are validated on five different cases of MuJoCo. Results seem good when compared to the STP ones. Compared to policy gradient methods, the results seem much better. Strengths: + The paper presents a small but interesting and well-motivated addition to the original algorithm STP. I particularly liked how straightforward the final algorithm is: applying momentum and sampling according to the Lipschitz constants. + At least at a first glance the results look good. Compared to STP in figure 1 there is a clear improvement not only in the final optimum but also in the speed of attaining the said optimum. + I liked a lot the presentation and clarity of writing. While quite mathematically dense, it was easy to follow the big story and understand that underlying points. Weaknesses: + While interesting and useful, I am not completely convinced whether the added novelty over (Bergou et al, 2019) is significant enough. At the end of the day, the final algorithm is the conglomeration of two existing algorithms, that is STP and momentum. STP is very similar to the final algorithm, after all it is the basis for it. The authors argue that it is not trivial to select the next points under the momentum term. To this end, they propose to rely on yet another existing approach, that is the virtual iterates analysis from (Yang et al. 2016). However, it is not clear why these points are *optimal*, what is so *non-trivial* about selecting them? This is basically skimmed over in two lines. + In the strongly convex case one assumption (knowing the f(x*) ) is replaced with another assumption, that all points lie on a hypersphere (|s|_2=1). I suppose this would assume a spherical normalization of the input space. While this is not an unrealistic assumption, it does place a constraint which could be problematic in the case of high dimensions for s? In that case the high dimensionality would render distances rather unreliable and in turn could hurt convergence? This is also perhaps the reason that only the MuJoCo enviroments were tested? In general, I would say that the strongly convex case was discussed less clearly and it is not exactly clear the final result. In the end, eq (25) does contain f(x*), whereas in the convex case K does not (K approx 2 R_0^2 L ?_D/(??_D^2). + Some statements are unclear. ++ In p. 2 some symbols are not explained, e.g., ?. While it is quite clear for peopled versed in the field, in my opinion it is bad practice to leave notation not explained. ++ In assumption 3.1 seems rather trivial? Wouldn*t ?_D by definition be always positive, since is the expectation of a squared norm (always positive)? Does this need to be an assumption? ++ Between eq. (11) and (12) there is reference to (35)? What is (35)? ++ It is not clear in practice how the importance sampling is performed. In Algorithm 2 the probabilities p_i are defined as function inputs and then never updated. Is that true? If yes, how is p_i decided in the first place? What is the connection to the Lipschitz constants L_i? + A highly relevant field appears to be Bayesian Optimization, where also one cannot compute gradients and must optimize a black-box function. Some relevant recent works are [1] and [2] for continuous and discrete inputs. It would be interesting to discuss what are the distinct differences with bayesian optimization methods in [1] and [2]. + I would say that the paper is rather on the light side regarding experiments. Only MuJoCo is used as an experimental setup. It would be nice to also report results on synthetic experiments with known functions to better understand the limitations of the algorithm. Synthetic and realistic setups can be found in [1] and [2]. What is more, the experimental choices are not entirely clear. What is the *predefined reward threshold* and why was that chosen? For instance, the leaderboard for *Swimmer* is in: https://www.endtoend.ai/envs/gym/mujoco/swimmer/. How does the proposed algorithm fair compared to these works? Also, *maybe* it would be interesting to compare even against [1] or [2] (I guess [2] is harder as it is for discete inputs), assuming that a relatively low number of iterations is performed. [1] BOCK: Bayesian Optimization with Cylindrical Kernels, C. Oh, E. Gavves, M. Welling, ICML 2018 [2] BOCS: Bayesian Optimization of Combinatorial Structures, R. Baptista, M. Poloczek, ICML 2018\",\n          \" Summary: This paper describes a contextual encoding scheme for reconstruction of 3D pointclouds from 2D images. An encoder outputs the parameters of a hierarchy of reconstruction networks that can be applied in succession to map random samples on a unit sphere to the surface of the reconstructed shape. Strengths: The author*s model was quite novel in my opinion. Deep 2D->3D is becoming a crowded space and there are many other models that encode image inputs, and many others that perform recursive or composition-based decoding. However, the particular link here was interesting, and I appreciate the small number of parameters resulting in solid reconstruction performance. While most related work was covered well, I believe the authors could have a more up-to-date list of recent work that reconstructs triangle-mesh representations from images [A-C] (especially since several of these methods has an architecture that involves encoding and subsequent compositional refinement). Some of the reconstructions shown in this paper are quite impressive, and the quantitative results show outperforming 2 recent methods. I did appreciate also the novel path-based evaluation of shape accuracy in the Appendix, although it would have been helpful to see more discussion of this in the main paper. Areas for improvement: I found that the core technical description was quite brief and would have benefited from simply more detail and space. You have argued that your method is sensible to try (cog. sci motivations), and shown that one instance works, but what can we expect in a more mathematical or general sense? Can any sizes of encoder and mapping network fit together? How does the number of mapping layers effect performance? Won*t we eventually expect vanishing/exploding gradients with particular activation and can one address this in some way? I note that recent papers in this field tend to perform significantly more extensive experimental evaluation, typically selecting a wider range of competitors and using a number of more standardized metrics including IOU, F1 score and CD and typically repeating these at a variety of resolutions or on additional datasets or category splits etc. Decision: Weak reject because the idea is quite interesting, but I believe a more thorough explanation and expanded experimental comparison would be of great help to ensure the community can appreciate this work. Additional citations suggested: [A] Pixel2Mesh: Generating 3D Mesh Models from Single RGB Images. Wang, Zhang, Li, Fu, Liu and Jiang. ECCV 2018. [B] MeshCNN: A Network with an Edge. Hanocka, Hertz, Fish, Giryes, Fleishman and Cohen-Or. SIGGRAPH 2019. [C] GEOMetrics: Exploiting Structure for Graph-Encoded Objects. Smith, Fujimoto, Romero and Meger. ICML 2019.\",\n          \"Review:###The paper proposes a learning-based adaptive compressed sensing framework in which both the sampling and the task functions (e.g., classification) are learned jointly end-to-end. The main contribution includes using the Gumbel-softmax trick to relax categorical distributions and use back-propagation to estimate the gradient jointly with the tas neural network. The proposed solution has the flexibility of able to be used in several different tasks, such as inverse problems ( super-resolution or image completion) or classification tasks. The paper is very well written. The paper locates itself well in current baselines and explains Experiments mostly well. However, there are significant limitations in demonstrating the effectiveness/impact of the proposed technique: 1) The only comparison to another non-fixed sampling baseline is Kool et al. 2019. The visualization and a thorough comparison were missing in MNIST classification. This baseline was also missing in image reconstruction. 2) Compressive Sensing incorporates vast literature of algorithms focusing on different aspects of improvements; algorithms focused on classification and inverse problems. Even if done disjointly, how does the proposed joint learning is compared to those algorithms in these domains? 3) Top row of Figure 3 nicely explains how the learned sampling paradigm performs compared to other mechanisms (such as uniform, random, low-pass). But there is no comparision against other non-fixed techniques.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_contentlength\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1611,\n        \"min\": 107,\n        \"max\": 24287,\n        \"num_unique_values\": 3773,\n        \"samples\": [\n          1057,\n          125,\n          4525\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a84038bf-faed-4314-a8b2-597500fbdff1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>publish_time</th>\n",
              "      <th>abstract</th>\n",
              "      <th>keyword</th>\n",
              "      <th>tL_DL</th>\n",
              "      <th>titlelength</th>\n",
              "      <th>paper_decision_time</th>\n",
              "      <th>paper_decision</th>\n",
              "      <th>paper_decision_comment</th>\n",
              "      <th>paper_decision_commentlength</th>\n",
              "      <th>review_publish_time</th>\n",
              "      <th>reviewer_level</th>\n",
              "      <th>paper_score</th>\n",
              "      <th>rate</th>\n",
              "      <th>review_score_one</th>\n",
              "      <th>review_score_two</th>\n",
              "      <th>review_score_three</th>\n",
              "      <th>review</th>\n",
              "      <th>review_contentlength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Carpe Diem, Seize the Samples Uncertain *at th...</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###The performance of deep neural net...</td>\n",
              "      <td>Keywords:###batch selection, uncertain sample,...</td>\n",
              "      <td>TL;DR:###We explore the issue of truly uncerta...</td>\n",
              "      <td>97</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Reject</td>\n",
              "      <td>Comment:###The authors propose a new mini-batc...</td>\n",
              "      <td>847</td>\n",
              "      <td>26 Oct 2019 (modified: 23 Nov 2019) 15 Nov 2019</td>\n",
              "      <td>Experience Assessment:###I have published in t...</td>\n",
              "      <td>Rating:###3: Weak Reject</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Review Assessment: Thoroughness In Paper Readi...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Exp...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>This paper proposes Recency Bias, an adaptive...</td>\n",
              "      <td>5156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Carpe Diem, Seize the Samples Uncertain *at th...</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###The performance of deep neural net...</td>\n",
              "      <td>Keywords:###batch selection, uncertain sample,...</td>\n",
              "      <td>TL;DR:###We explore the issue of truly uncerta...</td>\n",
              "      <td>97</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Reject</td>\n",
              "      <td>Comment:###The authors propose a new mini-batc...</td>\n",
              "      <td>847</td>\n",
              "      <td>23 Oct 2019 (modified: 06 Nov 2019) 15 Nov 2019</td>\n",
              "      <td>Experience Assessment:###I have read many pape...</td>\n",
              "      <td>Rating:###3: Weak Reject</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Review Assessment: Thoroughness In Paper Readi...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Exp...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>Review:###This paper proposes an interesting h...</td>\n",
              "      <td>1877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Carpe Diem, Seize the Samples Uncertain *at th...</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###The performance of deep neural net...</td>\n",
              "      <td>Keywords:###batch selection, uncertain sample,...</td>\n",
              "      <td>TL;DR:###We explore the issue of truly uncerta...</td>\n",
              "      <td>97</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Reject</td>\n",
              "      <td>Comment:###The authors propose a new mini-batc...</td>\n",
              "      <td>847</td>\n",
              "      <td>17 Oct 2019 (modified: 06 Nov 2019) 15 Nov 2019</td>\n",
              "      <td>Experience Assessment:###I do not know much ab...</td>\n",
              "      <td>Rating:###6: Weak Accept</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Review Assessment: Thoroughness In Paper Readi...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Exp...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>Review:###This paper explores a well motivated...</td>\n",
              "      <td>2026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Prestopping: How Does Early Stopping Help Gene...</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###Noisy labels are very common in re...</td>\n",
              "      <td>Keywords:###noisy label, label noise, robustne...</td>\n",
              "      <td>TL;DR:###We propose a novel two-phase training...</td>\n",
              "      <td>90</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Reject</td>\n",
              "      <td>Comment:###This paper focuses on avoiding over...</td>\n",
              "      <td>940</td>\n",
              "      <td>30 Oct 2019 (modified: 06 Nov 2019) 14 Nov 201...</td>\n",
              "      <td>Experience Assessment:###I have read many pape...</td>\n",
              "      <td>Rating:###3: Weak Reject</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Review Assessment: Thoroughness In Paper Readi...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Exp...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>Review:###This paper proposes a training strat...</td>\n",
              "      <td>2640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Prestopping: How Does Early Stopping Help Gene...</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###Noisy labels are very common in re...</td>\n",
              "      <td>Keywords:###noisy label, label noise, robustne...</td>\n",
              "      <td>TL;DR:###We propose a novel two-phase training...</td>\n",
              "      <td>90</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Reject</td>\n",
              "      <td>Comment:###This paper focuses on avoiding over...</td>\n",
              "      <td>940</td>\n",
              "      <td>30 Oct 2019 (modified: 06 Nov 2019) 14 Nov 201...</td>\n",
              "      <td>Experience Assessment:###I have read many pape...</td>\n",
              "      <td>Rating:###6: Weak Accept</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Review Assessment: Thoroughness In Paper Readi...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Exp...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>Review:###This paper presents a training appro...</td>\n",
              "      <td>1418</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a84038bf-faed-4314-a8b2-597500fbdff1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a84038bf-faed-4314-a8b2-597500fbdff1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a84038bf-faed-4314-a8b2-597500fbdff1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2c8011c0-d949-4483-88e1-531274c0f993\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c8011c0-d949-4483-88e1-531274c0f993')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2c8011c0-d949-4483-88e1-531274c0f993 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               title  \\\n",
              "0  Carpe Diem, Seize the Samples Uncertain *at th...   \n",
              "1  Carpe Diem, Seize the Samples Uncertain *at th...   \n",
              "2  Carpe Diem, Seize the Samples Uncertain *at th...   \n",
              "3  Prestopping: How Does Early Stopping Help Gene...   \n",
              "4  Prestopping: How Does Early Stopping Help Gene...   \n",
              "\n",
              "                          publish_time  \\\n",
              "0  26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "1  26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "2  26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "3  26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "4  26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "\n",
              "                                            abstract  \\\n",
              "0  Abstract:###The performance of deep neural net...   \n",
              "1  Abstract:###The performance of deep neural net...   \n",
              "2  Abstract:###The performance of deep neural net...   \n",
              "3  Abstract:###Noisy labels are very common in re...   \n",
              "4  Abstract:###Noisy labels are very common in re...   \n",
              "\n",
              "                                             keyword  \\\n",
              "0  Keywords:###batch selection, uncertain sample,...   \n",
              "1  Keywords:###batch selection, uncertain sample,...   \n",
              "2  Keywords:###batch selection, uncertain sample,...   \n",
              "3  Keywords:###noisy label, label noise, robustne...   \n",
              "4  Keywords:###noisy label, label noise, robustne...   \n",
              "\n",
              "                                               tL_DL  titlelength  \\\n",
              "0  TL;DR:###We explore the issue of truly uncerta...           97   \n",
              "1  TL;DR:###We explore the issue of truly uncerta...           97   \n",
              "2  TL;DR:###We explore the issue of truly uncerta...           97   \n",
              "3  TL;DR:###We propose a novel two-phase training...           90   \n",
              "4  TL;DR:###We propose a novel two-phase training...           90   \n",
              "\n",
              "                   paper_decision_time      paper_decision  \\\n",
              "0  20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Reject   \n",
              "1  20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Reject   \n",
              "2  20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Reject   \n",
              "3  20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Reject   \n",
              "4  20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Reject   \n",
              "\n",
              "                              paper_decision_comment  \\\n",
              "0  Comment:###The authors propose a new mini-batc...   \n",
              "1  Comment:###The authors propose a new mini-batc...   \n",
              "2  Comment:###The authors propose a new mini-batc...   \n",
              "3  Comment:###This paper focuses on avoiding over...   \n",
              "4  Comment:###This paper focuses on avoiding over...   \n",
              "\n",
              "   paper_decision_commentlength  \\\n",
              "0                           847   \n",
              "1                           847   \n",
              "2                           847   \n",
              "3                           940   \n",
              "4                           940   \n",
              "\n",
              "                                 review_publish_time  \\\n",
              "0    26 Oct 2019 (modified: 23 Nov 2019) 15 Nov 2019   \n",
              "1    23 Oct 2019 (modified: 06 Nov 2019) 15 Nov 2019   \n",
              "2    17 Oct 2019 (modified: 06 Nov 2019) 15 Nov 2019   \n",
              "3  30 Oct 2019 (modified: 06 Nov 2019) 14 Nov 201...   \n",
              "4  30 Oct 2019 (modified: 06 Nov 2019) 14 Nov 201...   \n",
              "\n",
              "                                      reviewer_level  \\\n",
              "0  Experience Assessment:###I have published in t...   \n",
              "1  Experience Assessment:###I have read many pape...   \n",
              "2  Experience Assessment:###I do not know much ab...   \n",
              "3  Experience Assessment:###I have read many pape...   \n",
              "4  Experience Assessment:###I have read many pape...   \n",
              "\n",
              "                paper_score  rate  \\\n",
              "0  Rating:###3: Weak Reject   3.0   \n",
              "1  Rating:###3: Weak Reject   3.0   \n",
              "2  Rating:###6: Weak Accept   6.0   \n",
              "3  Rating:###3: Weak Reject   3.0   \n",
              "4  Rating:###6: Weak Accept   6.0   \n",
              "\n",
              "                                    review_score_one  \\\n",
              "0  Review Assessment: Thoroughness In Paper Readi...   \n",
              "1  Review Assessment: Thoroughness In Paper Readi...   \n",
              "2  Review Assessment: Thoroughness In Paper Readi...   \n",
              "3  Review Assessment: Thoroughness In Paper Readi...   \n",
              "4  Review Assessment: Thoroughness In Paper Readi...   \n",
              "\n",
              "                                    review_score_two  \\\n",
              "0  Review Assessment: Checking Correctness Of Exp...   \n",
              "1  Review Assessment: Checking Correctness Of Exp...   \n",
              "2  Review Assessment: Checking Correctness Of Exp...   \n",
              "3  Review Assessment: Checking Correctness Of Exp...   \n",
              "4  Review Assessment: Checking Correctness Of Exp...   \n",
              "\n",
              "                                  review_score_three  \\\n",
              "0  Review Assessment: Checking Correctness Of Der...   \n",
              "1  Review Assessment: Checking Correctness Of Der...   \n",
              "2  Review Assessment: Checking Correctness Of Der...   \n",
              "3  Review Assessment: Checking Correctness Of Der...   \n",
              "4  Review Assessment: Checking Correctness Of Der...   \n",
              "\n",
              "                                              review  review_contentlength  \n",
              "0   This paper proposes Recency Bias, an adaptive...                  5156  \n",
              "1  Review:###This paper proposes an interesting h...                  1877  \n",
              "2  Review:###This paper explores a well motivated...                  2026  \n",
              "3  Review:###This paper proposes a training strat...                  2640  \n",
              "4  Review:###This paper presents a training appro...                  1418  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# first of all we need to import the dataset\n",
        "# we will use pandas to import the dataset from 2020\n",
        "url = \"./tp_2020conference.xlsx\"\n",
        "df = pd.read_excel(url)\n",
        "\n",
        "# printing some general information about the dataset downloaded\n",
        "print(df.shape)\n",
        "print(df.columns)\n",
        "df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e121d93",
      "metadata": {
        "id": "2e121d93"
      },
      "source": [
        "As we can observe, the dataset contains 19 columns and 7,766 rows. However, the rows are not all unique, the same paper may appear multiple times, as each paper typically receives more than one review before being accepted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5eb635bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eb635bc",
        "outputId": "62e46820-0c4c-4550-bb8a-e60538cba73b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "title                              0\n",
            "publish_time                       0\n",
            "abstract                           0\n",
            "keyword                          867\n",
            "tL_DL                           1977\n",
            "titlelength                        0\n",
            "paper_decision_time                6\n",
            "paper_decision                  1075\n",
            "paper_decision_comment          1033\n",
            "paper_decision_commentlength       0\n",
            "review_publish_time                0\n",
            "reviewer_level                     0\n",
            "paper_score                        0\n",
            "rate                            6346\n",
            "review_score_one                   0\n",
            "review_score_two                   0\n",
            "review_score_three                 0\n",
            "review                             0\n",
            "review_contentlength               0\n",
            "dtype: int64\n",
            "\n",
            "--- title ---\n",
            "title\n",
            "Reanalysis of Variance Reduced Temporal Difference Learning | OpenReview                   5\n",
            "Equivariant Entity-Relationship Networks | OpenReview                                      5\n",
            "Recurrent Hierarchical Topic-Guided Neural Language Models | OpenReview                    5\n",
            "Statistically Consistent Saliency Estimation | OpenReview                                  5\n",
            "MODELLING BIOLOGICAL ASSAYS WITH ADAPTIVE DEEP KERNEL LEARNING | OpenReview                5\n",
            "                                                                                          ..\n",
            "Learning Human Postural Control with Hierarchical Acquisition Functions | OpenReview       2\n",
            "PROTOTYPE-ASSISTED ADVERSARIAL LEARNING FOR UNSUPERVISED DOMAIN ADAPTATION | OpenReview    2\n",
            "Regional based query in graph active learning | OpenReview                                 2\n",
            "RL-LIM: Reinforcement Learning-based Locally Interpretable Modeling | OpenReview           2\n",
            "A Theory of Usable Information under Computational Constraints | OpenReview                2\n",
            "Name: count, Length: 2558, dtype: int64\n",
            "\n",
            "--- publish_time ---\n",
            "publish_time\n",
            "26 Sep 2019 (modified: 20 Dec 2019)    6684\n",
            "26 Sep 2019 (modified: 28 Nov 2019)    1005\n",
            "26 Sep 2019 (modified: 21 Dec 2019)      28\n",
            "26 Sep 2019 (modified: 10 Dec 2019)      15\n",
            "26 Sep 2019 (modified: 06 Dec 2019)       8\n",
            "26 Sep 2019 (modified: 19 Dec 2019)       6\n",
            "26 Sep 2019 (modified: 08 Dec 2019)       3\n",
            "26 Sep 2019 (modified: 18 Dec 2019)       3\n",
            "26 Sep 2019 (modified: 14 Dec 2019)       3\n",
            "26 Sep 2019 (modified: 11 Dec 2019)       3\n",
            "26 Sep 2019 (modified: 09 Dec 2019)       3\n",
            "26 Sep 2019 (modified: 07 Dec 2019)       3\n",
            "26 Sep 2019 (modified: 12 Dec 2019)       2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- abstract ---\n",
            "abstract\n",
            "Abstract:###Temporal difference (TD) learning is a popular algorithm for policy evaluation in reinforcement learning, but the vanilla TD can substantially suffer from the inherent optimization variance. A variance reduced TD (VRTD) algorithm was proposed by Korda and La (2015), which applies the variance reduction technique directly to the online TD learning with Markovian samples. In this work, we first point out the technical errors in the analysis of VRTD in Korda and La (2015), and then provide a mathematically solid analysis of the non-asymptotic convergence of VRTD and its variance reduction performance. We show that VRTD is guaranteed to converge to a neighborhood of the fixed-point solution of TD at a linear convergence rate. Furthermore, the variance error (for both i.i.d. and Markovian sampling) and the bias error (for Markovian sampling) of VRTD are significantly reduced by the batch size of variance reduction in comparison to those of vanilla TD.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         5\n",
            "Abstract:###Due to its extensive use in databases, the relational model is ubiquitous in representing big-data. However, recent progress in deep learning with relational data has been focused on (knowledge) graphs. In this paper we propose Equivariant Entity-Relationship Networks, the class of parameter-sharing neural networks derived from the entity-relationship model. We prove that our proposed feed-forward layer is the most expressive linear layer under the given equivariance constraints, and subsumes recently introduced equivariant models for sets, exchangeable tensors, and graphs. The proposed feed-forward layer has linear complexity in the the data and can be used for both inductive and transductive reasoning about relational databases, including database embedding, and the prediction of missing records. This, provides a principled theoretical foundation for the application of deep learning to one of the most abundant forms of data.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             5\n",
            "Abstract:###To simultaneously capture syntax and semantics from a text corpus, we propose a new larger-context language model that extracts recurrent hierarchical semantic structure via a dynamic deep topic model to guide natural language generation. Moving beyond a conventional language model that ignores long-range word dependencies and sentence order, the proposed model captures not only intra-sentence word dependencies, but also temporal transitions between sentences and inter-sentence topic dependences. For inference, we develop a hybrid of stochastic-gradient MCMC and recurrent autoencoding variational Bayes. Experimental results on a variety of real-world text corpora demonstrate that the proposed model not only outperforms state-of-the-art larger-context language models, but also learns interpretable recurrent multilayer topics and generates diverse sentences and paragraphs that are syntactically correct and semantically coherent.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             5\n",
            "Abstract:###The use of deep learning for a wide range of data problems has increased the need for understanding and diagnosing these models, and deep learning interpretation techniques have become an essential tool for data analysts. Although numerous model interpretation methods have been proposed in recent years, most of these procedures are based on heuristics with little or no theoretical guarantees. In this work, we propose a statistical framework for saliency estimation for black box computer vision models. We build a model-agnostic estimation procedure that is statistically consistent and passes the saliency checks of Adebayo et al. (2018). Our method requires solving a linear program, whose solution can be efficiently computed in polynomial time. Through our theoretical analysis, we establish an upper bound on the number of model evaluations needed to recover the region of importance with high probability, and build a new perturbation scheme for estimation of local gradients that is shown to be more efficient than the commonly used random perturbation schemes. Validity of the new method is demonstrated through sensitivity analysis.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                5\n",
            "Abstract:###Due to the significant costs of data generation, many prediction tasks within drug discovery are by nature few-shot regression (FSR) problems, including accurate modelling of biological assays. Although a number of few-shot classification and reinforcement learning methods exist for similar applications, we find relatively few FSR methods meeting the performance standards required for such tasks under real-world constraints. Inspired by deep kernel learning, we develop a novel FSR algorithm that is better suited to these settings. Our algorithm consists of learning a deep network in combination with a kernel function and a differentiable kernel algorithm. As the choice of the kernel is critical, our algorithm learns to find the appropriate one for each task during inference. It thus performs more effectively with complex task distributions, outperforming current state-of-the-art algorithms on both toy and novel, real-world benchmarks that we introduce herein. By introducing novel benchmarks derived from biological assays, we hope that the community will progress towards the development of FSR algorithms suitable for use in noisy and uncertain environments such as drug discovery.                                                                                                                                                                                                                                                                                                                                                                                                                                                            5\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ..\n",
            "Abstract:###Learning control policies in robotic tasks requires a large number of interactions due to small learning rates, bounds on the updates or unknown constraints. In contrast humans can infer protective and safe solutions after a single failure or unexpected observation. In order to reach similar performance, we developed a hierarchical Bayesian optimization algorithm that replicates the cognitive inference and memorization process for avoiding failures in motor control tasks. A Gaussian Process implements the modeling and the sampling of the acquisition function. This enables rapid learning with large learning rates while a mental replay phase ensures that policy regions that led to failures are inhibited during the sampling process. The features of the hierarchical Bayesian optimization method are evaluated in a simulated and physiological humanoid postural balancing task. We quantitatively compare the human learning performance to our learning approach by evaluating the deviations of the center of mass during training. Our results show that we can reproduce the efficient learning of human subjects in postural control tasks which provides a testable model for future physiological motor control tasks. In these postural control tasks, our method outperforms standard Bayesian Optimization in the number of interactions to solve the task, in the computational demands and in the frequency of observed failures.                                                                                                                                                                                                                         2\n",
            "Abstract:###This paper presents a generic framework to tackle the crucial class mismatch problem in unsupervised domain adaptation (UDA) for multi-class distributions. Previous adversarial learning methods condition domain alignment only on pseudo labels, but noisy and inaccurate pseudo labels may perturb the multi-class distribution embedded in probabilistic predictions, hence bringing insufficient alleviation to the latent mismatch problem. Compared with pseudo labels, class prototypes are more accurate and reliable since they summarize over all the instances and are able to represent the inherent semantic distribution shared across domains. Therefore, we propose a novel Prototype-Assisted Adversarial Learning (PAAL) scheme, which incorporates instance probabilistic predictions and class prototypes together to provide reliable indicators for adversarial domain alignment. With the PAAL scheme, we align both the instance feature representations and class prototype representations to alleviate the mismatch among semantically different classes. Also, we exploit the class prototypes as proxy to minimize the within-class variance in the target domain to mitigate the mismatch among semantically similar classes. With these novelties, we constitute a Prototype-Assisted Conditional Domain Adaptation (PACDA) framework which well tackles the class mismatch problem. We demonstrate the good performance and generalization ability of the PAAL scheme and also PACDA framework on two UDA tasks, i.e., object recognition (Office-Home,ImageCLEF-DA, andOffice) and synthetic-to-real semantic segmentation (GTA5?CityscapesandSynthia?Cityscapes).    2\n",
            "Abstract:###Graph convolution networks (GCN) have emerged as a leading method to classify nodes and graphs. These GCN have been combined with active learning (AL) methods, when a small chosen set of tagged examples can be used. Most AL-GCN use the sample class uncertainty as selection criteria, and not the graph. In contrast, representative sampling uses the graph, but not the prediction. We propose to combine the two and query nodes based on the uncertainty of the graph around them. We here propose two novel methods to select optimal nodes in AL-GCN that explicitly use the graph information to query for optimal nodes. The first method named regional uncertainty is an extension of the classical entropy measure, but instead of sampling nodes with high entropy, we propose to sample nodes surrounded by nodes of different classes, or nodes with high ambiguity. The second method called Adaptive Page-Rank is an extension of the page-rank algorithm, where nodes that have a low probability of being reached by random walks from tagged nodes are selected. We show that the latter is optimal when the fraction of tagged nodes is low, and when this fraction grows to one over the average degree, the regional uncertainty performs better than all existing methods. While we have tested these methods on graphs, such methods can be extended to any classification problem, where a distance can be defined between the input samples.                                                                                                                                                                                                                             2\n",
            "Abstract:###Understanding black-box machine learning models is important towards their widespread adoption. However, developing globally interpretable models that explain the behavior of the entire model is challenging. An alternative approach is to explain black-box models through explaining individual prediction using a locally interpretable model. In this paper, we propose a novel method for locally interpretable modeling -- Reinforcement Learning-based Locally Interpretable Modeling (RL-LIM). RL-LIM employs reinforcement learning to select a small number of samples and distill the black-box model prediction into a low-capacity locally interpretable model. Training is guided with a reward that is obtained directly by measuring agreement of the predictions from the locally interpretable model with the black-box model. RL-LIM near-matches the overall prediction performance of black-box models while yielding human-like interpretability, and significantly outperforms state of the art locally interpretable models in terms of overall prediction performance and fidelity.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          2\n",
            "Abstract:###We propose a new framework for reasoning about information in complex systems. Our foundation is based on a variational extension of Shannons information theory that takes into account the modeling power and computational constraints of the observer. The resulting predictive F-information encompasses mutual information and other notions of informativeness such as the coefficient of determination. Unlike Shannons mutual information and in violation of the data processing inequality, F-information can be created through computation. This is consistent with deep neural networks extracting hierarchies of progressively more informative features in representation learning. Additionally, we show that by incorporating computational constraints, F-information can be reliably estimated from data even in high dimensions with PAC-style guarantees. Empirically, we demonstrate predictive F-information is more effective than mutual information for structure learning and fair representation learning.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                2\n",
            "Name: count, Length: 2558, dtype: int64\n",
            "\n",
            "--- keyword ---\n",
            "keyword\n",
            "NaN                                                                                                   867\n",
            "Keywords:###variational autoencoder, generative adversarial network                                     7\n",
            "Keywords:###semi-supervised learning                                                                    6\n",
            "Keywords:###deep policy gradient methods, deep reinforcement learning, trpo, ppo                        6\n",
            "Keywords:###Imitation Learning, Reinforcement Learning                                                  6\n",
            "                                                                                                     ... \n",
            "Keywords:###neural network, alternating minimization, global convergence                                2\n",
            "Keywords:###Domain Adaptation, Transfer Learning, Adversarial Learning                                  2\n",
            "Keywords:###Human Postural Control Model, Hierarchical Bayesian Optimization, Acquisition Function      2\n",
            "Keywords:###Active Learning, Graph Convolution Networks, Graph, Graph Topology                          2\n",
            "Keywords:###Interpretability, Explanable AI, Explanability                                              2\n",
            "Name: count, Length: 2270, dtype: int64\n",
            "\n",
            "--- tL_DL ---\n",
            "tL_DL\n",
            "NaN                                                                                                                                                                                                                1977\n",
            "TL;DR:###This paper provides a rigorous study of the variance reduced TD learning and characterizes its advantage over vanilla TD learning                                                                            5\n",
            "TL;DR:###How to use cross-entropy loss for zero shot learning with soft labeling on unseen classes : a simple and effective solution that achieves state-of-the-art performance on five ZSL benchmark datasets.       5\n",
            "TL;DR:###A novel Gram-Gauss-Newton method to train neural networks, inspired by neural tangent kernel and Gauss-Newton method, with fast convergence speed both theoretically and experimentally.                     5\n",
            "TL;DR:###We investigate the modelling of biological assays using deep kernel learning in few-shot settings.                                                                                                           5\n",
            "                                                                                                                                                                                                                   ... \n",
            "TL;DR:###Dimensionality reduction algorithm to visualise text with network information, for example an email corpus or co-authorships.                                                                                2\n",
            "TL;DR:###We propose a novel Deep Learning Alternating Minimization (DLAM) algorithm to solve the fully- connected neural network problem with convergence guarantee                                                   2\n",
            "TL;DR:###We propose a reliable conditional adversarial learning scheme along with a simple, generic yet effective framework for UDA tasks.                                                                            2\n",
            "TL;DR:###This paper presents a computational model for efficient human postural control adaptation based on hierarchical acquisition functions with well-known features.                                              2\n",
            "TL;DR:###Graph-oriented approaches to Active Learning for node classification                                                                                                                                         2\n",
            "Name: count, Length: 1911, dtype: int64\n",
            "\n",
            "--- titlelength ---\n",
            "titlelength\n",
            "78     182\n",
            "75     182\n",
            "90     175\n",
            "88     172\n",
            "69     169\n",
            "      ... \n",
            "150      3\n",
            "27       3\n",
            "137      3\n",
            "28       3\n",
            "129      2\n",
            "Name: count, Length: 123, dtype: int64\n",
            "\n",
            "--- paper_decision_time ---\n",
            "paper_decision_time\n",
            "20 Dec 2019 (modified: 20 Dec 2019)                                                                            6670\n",
            "2019-11-16 00:00:00                                                                                             191\n",
            "2019-11-15 00:00:00                                                                                             151\n",
            "2019-11-14 00:00:00                                                                                             130\n",
            "07 Nov 2019                                                                                                      82\n",
            "09 Nov 2019                                                                                                      79\n",
            "08 Nov 2019                                                                                                      73\n",
            "2019-11-13 00:00:00                                                                                              70\n",
            "2019-11-10 00:00:00                                                                                              52\n",
            "2019-11-11 00:00:00                                                                                              30\n",
            "2019-11-12 00:00:00                                                                                              22\n",
            "06 Nov 2019                                                                                                      18\n",
            "2019-11-19 00:00:00                                                                                              18\n",
            "2019-11-18 00:00:00                                                                                              18\n",
            "2019-12-10 00:00:00                                                                                              15\n",
            "20 Dec 2019 (modified: 20 Dec 2019) 21 Dec 2019                                                                  12\n",
            "2019-12-21 00:00:00                                                                                              12\n",
            "2019-11-20 00:00:00                                                                                              10\n",
            "2019-11-23 00:00:00                                                                                               9\n",
            "06 Dec 2019                                                                                                       8\n",
            "2019-11-27 00:00:00                                                                                               8\n",
            "2019-11-22 00:00:00                                                                                               7\n",
            "2019-11-21 00:00:00                                                                                               7\n",
            "20 Dec 2019 (modified: 20 Dec 2019) 21 Dec 2019 (modified: 21 Dec 2019)                                           6\n",
            "2019-11-17 00:00:00                                                                                               6\n",
            "2019-12-19 00:00:00                                                                                               6\n",
            "NaN                                                                                                               6\n",
            "2019-12-20 00:00:00                                                                                               3\n",
            "14 Nov 2019 (modified: 14 Nov 2019)                                                                               3\n",
            "2019-12-11 00:00:00                                                                                               3\n",
            "2019-12-14 00:00:00                                                                                               3\n",
            "2019-12-18 00:00:00                                                                                               3\n",
            "20 Dec 2019 (modified: 20 Dec 2019) 21 Dec 2019 (modified: 21 Dec 2019) 21 Dec 2019 (modified: 21 Dec 2019)       3\n",
            "08 Dec 2019                                                                                                       3\n",
            "07 Dec 2019                                                                                                       3\n",
            "07 Nov 2019 (modified: 07 Nov 2019)                                                                               3\n",
            "15 Nov 2019 15 Nov 2019                                                                                           3\n",
            "08 Nov 2019 08 Nov 2019                                                                                           3\n",
            "09 Dec 2019                                                                                                       3\n",
            "14 Nov 2019 (modified: 28 Nov 2019)                                                                               3\n",
            "2019-11-26 00:00:00                                                                                               3\n",
            "06 Nov 2019 (modified: 06 Nov 2019)                                                                               3\n",
            "21 Dec 2019 (modified: 21 Dec 2019)                                                                               3\n",
            "2019-12-12 00:00:00                                                                                               2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- paper_decision ---\n",
            "paper_decision\n",
            "Decision:###Reject                4638\n",
            "Decision:###Accept (Poster)       1588\n",
            "NaN                               1075\n",
            "Decision:###Accept (Spotlight)     320\n",
            "Decision:###Accept (Talk)          145\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- paper_decision_comment ---\n",
            "paper_decision_comment\n",
            "NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              1033\n",
            "Comment:###All three reviewers are consistently negative on this paper. Thus a reject is recommended.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              18\n",
            "Comment:###The paper is rejected based on unanimous reviews.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       14\n",
            "Comment:###The paper is proposed a rejection based on majority reviews.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             9\n",
            "Comment:###This paper constitutes interesting progress on an important topic; the reviewers identify certain improvements and directions for future work, and I urge the authors to continue to develop refinements and extensions.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 9\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ... \n",
            "Comment:###The paper proposes a new learning algorithm for deep neural networks that first reformulates the problem as a multi-convex and then uses an alternating update to solve. The reviewers are concerned about the closeness to previous work, comparisons with related work like dlADMM, and the difficulty of the dataset. While the authors proposed the possibility of addressing some of these issues, the reviewers feel that without actually addressing them, the paper is not yet ready for publication.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            2\n",
            "Comment:###The paper focuses on adversarial domain adaptation, and proposes an approach inspired from the DANN. The contribution lies in additional terms in the loss, aimed to i) align the source and target prototypes in each class (using pseudo labels for target examples); ii) minimize the variance of the latent representations for each class in the target domain. Reviews point out that the expected benefits of target prototypes might be ruined if the pseudo-labels are too noisy; they note that the specific problem needs be more clearly formalized and they regret the lack of clarity of the text. The sensitivity w.r.t. the hyper-parameter values needs be assessed more thoroughly. One also notes that SAFN is one of the baseline methods; but its best variant (with entropic regularization) is not considered, while the performance thereof is on par or greater than that of PACFA for ImageCLEF-Da; idem for AdapSeg (consider its multi-level variant) or AdvEnt with MinEnt. For these reasons, the paper seems premature for publication at ICLR 2020.                                                                                                                      2\n",
            "Comment:###The paper proposes hierarchical Bayesian optimization (HiBO) for learning control policies from a small number of environment interaction and applies it to the postural control of a humanoid. Both reviewers raised issues with the clarity of presentation, as well as contribution and overall fit to this venue. The authors response helped to clarify these issues only marginally. Therefore, primarily due to lack of clarity, I recommend rejecting this paper, but encourage the authors to improve the presentation as per the reviewers suggestions and resubmitting.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     2\n",
            "Comment:###The paper proposes a method for performing active learning on graph convolutional networks. In particular, instead of performing uncertainty-based sampling based on an individual node level, the authors propose to look at regional based uncertainty. They propose an efficient algorithm based on page rank. Empirically, they compare their method to several other leading methods, comparing favorably. Reviewers found the work poorly organized and difficult to read. The idea to use region based estimates is intuitive but feels like nothing more than just that. It*s not clear if there is a mathematical basis to justify such a method (e.g. an analysis of sample complexity as has been accomplished in other graph active learning problems, Dasarathy, Nowak, Zhu 2015). The idea requires further study and justification, and the paper needs an improved exposition. Finally, the authors were not anonymized on the PDF.                                                                                                                                                                                                                                                      2\n",
            "Comment:###The paper aims to find locally interpretable models, such that the local models are fit (w.r.t. the ground truth) and faithful (w.r.t. the global underlying black box model). The contribution of the paper is that the local model is trained from a subset of points, selected via an optimized importance weight function. The difference compared to Ren et al. (cited) is that the IW function is non-differentiable and optimized using Reinforcement Learning. A first concern (Rev#1, Rev#2) regards the positioning of the paper w.r.t. RL, as the actual optimization method could be any black-box optimization method: one wants to find the IW that maximizes the faithfulness. The rebuttal makes a good job in explaining the impact of using a non-differentiable IW function. A second concern (Rev#2) regards the interpretability of the IW underlying the local interpretable model. There is no doubt that the paper was considerably improved during the rebuttal period. However, the improvements raise additional questions (e.g. about selecting the IW depending on the distance to the probes). I encourage the authors to continue on this promising line of search.       2\n",
            "Name: count, Length: 2201, dtype: int64\n",
            "\n",
            "--- paper_decision_commentlength ---\n",
            "paper_decision_commentlength\n",
            "0       1033\n",
            "411       21\n",
            "101       21\n",
            "611       21\n",
            "396       21\n",
            "        ... \n",
            "2429       2\n",
            "581        2\n",
            "1665       2\n",
            "1001       2\n",
            "356        2\n",
            "Name: count, Length: 1142, dtype: int64\n",
            "\n",
            "--- review_publish_time ---\n",
            "review_publish_time\n",
            "23 Oct 2019 (modified: 06 Nov 2019)                                                                                                                                                                362\n",
            "24 Oct 2019 (modified: 06 Nov 2019)                                                                                                                                                                240\n",
            "22 Oct 2019 (modified: 06 Nov 2019)                                                                                                                                                                148\n",
            "23 Oct 2019 (modified: 06 Nov 2019) 15 Nov 2019                                                                                                                                                    131\n",
            "24 Oct 2019 (modified: 06 Nov 2019) 15 Nov 2019                                                                                                                                                     99\n",
            "                                                                                                                                                                                                  ... \n",
            "23 Oct 2019 (modified: 18 Nov 2019) 16 Nov 2019 (modified: 16 Nov 2019) 14 Nov 2019                                                                                                                  1\n",
            "21 Oct 2019 (modified: 14 Nov 2019) 16 Nov 2019 12 Nov 2019 (modified: 13 Nov 2019) 12 Nov 2019 (modified: 14 Nov 2019) 12 Nov 2019 (modified: 13 Nov 2019)                                          1\n",
            "24 Oct 2019 (modified: 19 Nov 2019) 16 Nov 2019 10 Nov 2019 (modified: 12 Nov 2019) 10 Nov 2019 (modified: 10 Nov 2019) 10 Nov 2019 (modified: 16 Nov 2019) 10 Nov 2019 (modified: 11 Nov 2019)      1\n",
            "25 Oct 2019 (modified: 03 Dec 2019) 16 Nov 2019                                                                                                                                                      1\n",
            "29 Oct 2019 (modified: 06 Nov 2019) 10 Nov 2019 10 Nov 2019                                                                                                                                          1\n",
            "Name: count, Length: 3128, dtype: int64\n",
            "\n",
            "--- reviewer_level ---\n",
            "reviewer_level\n",
            "Experience Assessment:###I have published one or two papers in this area.     2659\n",
            "Experience Assessment:###I have read many papers in this area.                2554\n",
            "Experience Assessment:###I have published in this field for several years.    1449\n",
            "Experience Assessment:###I do not know much about this area.                  1104\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- paper_score ---\n",
            "paper_score\n",
            "Rating:###3: Weak Reject    3166\n",
            "Rating:###6: Weak Accept    2487\n",
            "Rating:###1: Reject         1264\n",
            "Rating:###8: Accept          849\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- rate ---\n",
            "rate\n",
            "NaN    6346\n",
            "3.0     677\n",
            "6.0     380\n",
            "1.0     297\n",
            "8.0      66\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- review_score_one ---\n",
            "review_score_one\n",
            "Review Assessment: Thoroughness In Paper Reading:###I read the paper at least twice and used my best judgement in assessing the paper.    4188\n",
            "Review Assessment: Thoroughness In Paper Reading:###I read the paper thoroughly.                                                          2777\n",
            "Review Assessment: Thoroughness In Paper Reading:###I made a quick assessment of this paper.                                               625\n",
            "Review Assessment: Thoroughness In Paper Reading:###N/A                                                                                    176\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- review_score_two ---\n",
            "review_score_two\n",
            "Review Assessment: Checking Correctness Of Experiments:###I assessed the sensibility of the experiments.    4604\n",
            "Review Assessment: Checking Correctness Of Experiments:###I carefully checked the experiments.              2751\n",
            "Review Assessment: Checking Correctness Of Experiments:###I did not assess the experiments.                  232\n",
            "Review Assessment: Checking Correctness Of Experiments:###N/A                                                179\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- review_score_three ---\n",
            "review_score_three\n",
            "Review Assessment: Checking Correctness Of Derivations And Theory:###I assessed the sensibility of the derivations and theory.    4097\n",
            "Review Assessment: Checking Correctness Of Derivations And Theory:###I carefully checked the derivations and theory.              1599\n",
            "Review Assessment: Checking Correctness Of Derivations And Theory:###N/A                                                          1489\n",
            "Review Assessment: Checking Correctness Of Derivations And Theory:###I did not assess the derivations or theory.                   581\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- review ---\n",
            "review\n",
            "Review:###The paper presents an improvement to the task of transfer learning by being deliberate about which channels from the base model are most relevant to the new task at hand. It does this by apply attentive feature selection (AFS) to select channels or features that align well with the down stream task and attentive feature distillation (AFD) to pass on these features to the student network. In the process they do channel pruning there by decreasing the size of the network and enabling faster inference speeds. Their major argument is that plain transfer learning is redundant and wasteful and careful attention applied to selection of the features and channels to be transfered can lead to smaller faster models which in several cases presented in the paper provide superior performance. Paper is clear and concise and experimentally sound showing a real contribution to the body of knowledge in transfer learning and pruning.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         2\n",
            "Review:###This paper proposes a new oversampling method for class-imbalanced datasets, which is called Adversarial Minority Over-sampling (AMO). Its contribution is that it performs over-sampling using the samples of the majority classes, not the minority classes. It generates adversarial examples of the majority class and labels them as one of the minority classes. The purpose of using the majority class samples is that it can solve the problem of overfitting minority classes by using samples from minority classes too much, which is a typical problem of ordinary over-sampling techniques. For this purpose, the authors propose a new optimization objective that generates synthetic samples by transforming the majority class samples and devises a rejection criterion to determine whether the generated sample is appropriate, motivated by the concept of effective number of samples. They also proposed the distribution of the appropriate initial seed point of the generation through newly designed criteria. I do not think this paper is acceptable in the current state, and there exist some ambiguous issues where clarification and more supporting evidences are required. However, as a new novel approach to mitigate the over-fitting issue, if the following questions are answered reasonably, this paper may become acceptable. 1. As the authors mentioned consistently, the classifier g that generates adversarial examples is unreliable and potentially over-fitted to minority classes, which means that the classifier g cannot learn the general features for the minority classes. It is clear that the classifier g would make reasonable adversarial examples for the majority classes, but it is unclear that the generated examples by g are reasonable to be labeled as one of the minority classes, a target class. Although the classifier g would classify the generated example as the target class, it does not mean that it captured the general features of the target class and generated the adversarial sample using them. Instead, I think it is possible that the resulting synthetic example can be labeled as any minor class, not just as the target minor class. In the reported results, the proposed method would learn how to distinguish each major class from the last and fail to generalize in minority classes and make any example with the only constraint that it does not have the feature of starting (major) class, regardless what the target class is. Thus, I ask the authors to a) provide the evidence that the model g generates the samples with general features for each minor class and b) explain clearly how it is possible. c) I also suggest the authors to show the recall in addition to the accuracy in Tables 1 and 2. 2. I am wondering why f does not have to classify synthetic examples as their target classes, as stated right below Equation (2) in page 3. It seems reasonable for f to classify the example exactly like g. Even in Figure 4, it seems that the classifier g attempted to generate Truck class example, but it failed, as the model f classified it as Bird. It would be great if the authors clarify how the classifier work in this manner and what is the expected outcome of f. 3. Also, I am wondering why the accuracy of major class examples decrease from 2% to 7% consistently if AMO is applied to ERM or LDAM in CIFAR-10 and CIFAR-100 dataset. I conjecture it is because the features of the starting example are not fully erased. Also, I think that the proposed method affects the performance of the majority class in page 2. In this respect, I would like to see how many samples of major classes are correctly classified previously but misclassified after the model was trained with synthetic adversarial examples, to check the effect of adversarial examples on learning the major class. 4. It is a minor point, but it needs clarification on how the train/test set was constructed in both g and f, e.g., whether they have the exactly same training set.    1\n",
            " This manuscript proposes an over-sampling method for dealing with the imbalanced classification and long-trailed problems. The authors refer to their work as Advserarial Minority Over-sampling (AMO). The interesting aspect of this paper is that it explores adversarial perturbation (possibly of majority class) as a means of over-sampling for the minority class. The findings suggest that it could improve imbalanced learning. However, there are several major issues with the paper in its current form: - There is a recent publication with almost the same topic in ICCV 2019 that also explores using adversarial minority over sampling frameworks (published on arxiv on Apr 3, 2019 https://arxiv.org/pdf/1903.09730.pdf). Although that one is a bit different methodologically, the authors have not mentioned it, compare with it, nor discussed it. It is not clear where the current manuscript stands in comparison with the ICCV 2019 paper. - Given the above paper, the novelties of the proposed technique become marginal. - Another major issue with the paper is its methodological limitations. As the authors have also mentioned, it looks a bit like learning to classify the adversarial examples. It seems like this is a very effective method if we want to classify a majority (normal) class versus a minority (anomaly) class. Because when the model generates adversarial examples for any specific class the adversarial examples may cover all space of the samples minus the samples of that (normal) class. Therefore, the model does not learn the geometry of the minority class (as opposed to many state-of-the-art long-trailed classification models) and only learns the majority class. This is not itself a positive characteristic. - The authors have not provided any theoretical discussions/guarantees why adversarial examples should be a good means of learning the imbalanced distributions. Everything in the paper seems to be experimental and heuristic. - The accuracy metric provided by the authors is a bit misleading. For these cases of long-trailed classification models, Average Class Specific Accuracy and Geometric Mean (analogous to F1-score) are the most relevant ones to report, especially because experiments are conducted on multi-class settings. - The results in Table 2 show a highly imbalanced classification rate between majority and minority classes. This means that neither the proposed method nor the baselines could solve the problem. The differences between the proposed method and the baselines do not seem to be statistically significant. So, what is the purpose of this experiment!?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    1\n",
            "Review:###This paper proposes two approaches to quantify neuron importance in CNNs. The first method based on Shapley value computes the marginal contribution of each filter; and the second approach uses probabilistic variational inference. The algorithmic contribution is demonstrated with a suite of experiments on MNIST and Fashion-MNIST, using LeNet and VGG architectures. This paper should be rejected primarily because (1) the algorithms are not well justified either by theory or practice; (2) the two approaches described are loosely connected and therefore making the paper lack of focus; and (3) the experiments lack comparison with many other existing state-of-the-art neural compression methods. Specifically, this paper lacks theoretical and/or empirical justification on why individual neurons contribution during the learning process can be characterized equivalently as a coalitional game. How is the characteristic function chosen in practice? Does this depend on the neural network architecture in use? Further experiments should be provided to show ablation on this. The authors should also consider reporting the measurement in time for computing the Shapley value, in order to justify the computation feasibility. How well does the approximated solution compared to the optimal solution? Whats the time and performance tradeoff? In the experimental section, the author should consider providing details on how to choose the number of channels (for different layers) to prune based on the ranking. How does the pruning strategy affect the model performance? This paper can be strengthened by comparing with existing state-of-the-art compression methods such as knowledge distillation (Hinton et al), SqueezeNet, ShuffleNet and other quantization based methods.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1\n",
            "Review:###The authors define two new methods for ranking the influence of individual units on the output of convolutional networks. They show that some overlap exists between the units chosen by these two methods, they use these methods to select filters to visualize, and they use one of the methods to prune/compress trained convolutional networks. Their compression method outperforms prior work. Pros The neuron ranking method produces compressed models that compare favorably with prior work (Table 2). Cons I found the clarity of this paper overall to be somewhat poor. These points especially need to be addressed The acronyms for the baselines in table 2 are not defined or cited. Lack of clarity about the pruning experiment: Why is the Shapley value method not included here? I*m assuming NR stands for neuron ranking. Lack of clarity about visualizations: Are the rankings used to choose filters to visualize from Shapley values or neuron ranking? The units [1,8,3,7] don*t seem to be seem to all be selected by either method for MNIST conv1 in Table 1. I wasn*t convinced by the feature map visualization section, because as far as I can tell the unimportant nodes don*t look very different from the important nodes. Specifically, in both the important and unimportant node feature maps, a class example is clearly visible. Perhaps the authors could clarify what the critical difference is between these feature maps. The neuron ranking method seems to give only a marginal advantage over simple magnitude pruning. Overall The compression results seem strong in comparison to past work, but marginal in comparison to the simple baselines. The feature map visualizations were not compelling, and may require clarification. Comments *the deeper architecture also become wider* -- I*m not sure what this means. *the units in the network (both convolutional filters and nodes in fully connected layers) are not equally important when it comes to performing an inference task.* -- Morcos et al., 2018 seems relevant https://openreview.net/pdf?id=r1iuQjxCZ. *We visualize the most significant features which significantly show the significance of repeated and complementary features* -- I didn*t quite understand this. Typos gaining insight what the CNN -> gaining insight about what the CNN filter rankingse -> filter rankings in the the case on the other and                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     1\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ..\n",
            "Review:###This paper proposed a contextual temperature scaling to improve language modeling. The temperature model is parameterized using a deep neural network. Experiments on the language modeling datasets show some effects of the method. The idea of dynamic temperature scaling has been tried in other works and tasks (e.g., attended temperature scaling). The paper parameterizes this mechanism with DNNs for the language model. Though the idea looks interesting, it fails to explain why the scaling is better than other dynamic temperature scaling frameworks. The experiments are not solid. The baseline only includes Mos, which is not very strong. To validate whether this approach works with other LM of high-order attention or self-attention, a better baseline model is required (e.g., transformer, GPT). I would like to see this technique can help either NLU or NLG tasks, instead of just pure modeling. The case analysis section needs more examples instead of just cherry-picking few.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1\n",
            "Review:###This paper presents a strategy to automatically adjust the temperature scaling based on the context of words in a sentence for NLP. Experiments demonstrate that this approach can significantly improve perplexity scores on several datasets popular for NLP. NLP is not an area of research I*m very familiar with so this review is limited to my understanding of temperature scaling as a general technique to improve learning. As described in the paper, temperature scaling is a type of hyper-parameter estimation that adjusts the sensitivity of the softmax function as training evolves. The paper proposes to learn a function that given context, adjust the temperature automatically. This can be seen as a meta-learning method. I believe this can be a useful technique but before considering such an approach as a general strategy, more theoretical insights should be provided. The authors report on ablation studies that demonstrate some empirical benefits. However, until I see more theoretical analysis on how the method improves convergence or lead to better losses by smoothing out the output of the objective function, I remain skeptical of the usefulness of this as a general training method.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1\n",
            "Review:###The paper proposes a new loss function which adds to the training objective another term that pulls the current parameters of a neural network further away from the parameters at a previous time step. Intuitively, this aims to push the current parameters further to the local optimum. On a variety of benchmarks, optimizing the proposed loss function achieves better results than just optimizing the training loss. The paper is well written and easy to follow. However, I am not entirely convinced about the intuition of the proposed method and I think further investigation are necessary. While the method is simple and general, it also seems to be rather heuristic and requires carefully chosen hyperparameters. Having said that, the empirical evidence shows that the proposed loss function consistently improves performance. The following details should be addressed further: - I am a bit confused by the definition of the loss function. In Equation 1 it seems that the term on the left represents the training objective. If that is correct than Equation 2 second case contains the training objective twice? - F in Section 3 after Equation 2 is not properly defined - Could it happen that the proposed loss function leads to divergence, for example if the parameter from a previous time step theta^Tp is close to the optimum theta_star? - What is the motivation to use the L1 norm? How does this choice affect convergence compared to let*s L2 norm? - Section 4.1 typo in first paragraph: K instead of kappa - Section 4.1 the results would be more convincing if all networks were trained multiple times with a different random initialization and Table 1 would include the mean and std. - Why is no warm-up period used for the GAN experiments? - Section 4.3: why is kappa increase by 1% for the speech recognition experiments where as by 2% for all other experiments? - I suggest to increase the line width of all figures since they are somewhat hard to identify on a print version. - Why is the momentum set to 0.5 for SGD in the ablation study? Most frameworks use a default value of 0.9. - I would like to see the affect of the warm-up period to the performance in the ablation study. - How does the choice of learning rate schedule, such as for example cosine annealing, affect the loss function? post rebuttal ------------------ I thank the authors for clarifying my questions and providing additional experiments. I think that especially the additional ablation studies and reporting the mean and std of multiple trials make the contribution of the paper more convincing. Hence, I increased my score.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1\n",
            "Review:###This paper presents the retrospective loss to optimize neural network training. The idea behind the retrospective loss is to add a penalization term between the current model to the model from a few iterations before. Extensive experimental results on a wide range of datasets are provided to show the effectiveness of the retrospective loss. The retrospective loss is additionally controlled by two hyperparameters, the strength parameter K and the update frequency T_p. This loss, measured in L-1 norm, is added to the training objective. The geometric intuition of the added loss term is that this pushes the model away from the model at iteration T_p. The paper argues that this shrinks the parameter space of the loss function. One of the concern regards the writing of the paper. - Algorithm 1 and Figure 6 look very blurry, which I think are both below the publication standard. - The introduction could be written to be more helpful, such as providing more context on why the obtained experimental results are important (e.g. getting state-of-the-art results on the datasets studied in the experiments) - The Related Work contrasts with previous work which is not clear because the precise contribution has not been stated at the point. More detailed questions: - What are the standard deviations for the experimental results (as you reported in Table 4 but not in other experiments)? - I*m curious whether the use of L-1 norm is critical or not in the retrospective loss.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1\n",
            "Review:###This paper start merely by studying the graph reconstruction problem and prove that the intrinsic structure of this task itself automatically produces the complete definition of groups. it seems to be a novel result. Based on this result, one could construct embedding models that naturally accommodate all possible local graph patterns, and the paper also shows a few simulations. My main concern is that, while the focus on this work is the theoretical finding, there is no rigorous statement of it as a theorem. As a result, I am not exactly sure what the proofs in the appendix is trying to show. In addition, the proofs seems to be very trivial. For the algorithm section, I feel that it is also lacking in the sense that there is still no automatic way to choose which group to embed. It is also unclear what is the purpose of the simulation section. While it says *As theoretically analyzed in Section 3.2, and empirically shown above, continuous nonabelian groups are more reasonable choices for general tasks*, the advantage of continuous nonabelian groups are not so significant in the tables.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1\n",
            "Name: count, Length: 7765, dtype: int64\n",
            "\n",
            "--- review_contentlength ---\n",
            "review_contentlength\n",
            "1961    9\n",
            "2031    9\n",
            "2060    9\n",
            "1464    9\n",
            "1388    8\n",
            "       ..\n",
            "6764    1\n",
            "3754    1\n",
            "4679    1\n",
            "2534    1\n",
            "2026    1\n",
            "Name: count, Length: 3773, dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('deep learning', 591),\n",
              " ('reinforcement learning', 357),\n",
              " ('keywords:###reinforcement learning', 347),\n",
              " ('keywords:###deep learning', 305),\n",
              " ('representation learning', 236),\n",
              " ('generalization', 130),\n",
              " ('natural language processing', 125),\n",
              " ('generative models', 122),\n",
              " ('transfer learning', 120),\n",
              " ('interpretability', 111),\n",
              " ('robustness', 108),\n",
              " ('neural networks', 105),\n",
              " ('optimization', 103),\n",
              " ('unsupervised learning', 97),\n",
              " ('keywords:###meta-learning', 97),\n",
              " ('keywords:###adversarial examples', 90),\n",
              " ('graph neural networks', 86),\n",
              " ('keywords:###graph neural networks', 86),\n",
              " ('variational inference', 85),\n",
              " ('keywords:###deep reinforcement learning', 85)]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check if there are missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# count unique values per column\n",
        "for col in df.columns:\n",
        "    print(f\"\\n--- {col} ---\")\n",
        "    print(df[col].value_counts(dropna=False))\n",
        "\n",
        "# count and print unique keywords\n",
        "from collections import Counter\n",
        "\n",
        "keywords = df['keyword'].dropna().str.lower().str.split(';|,')\n",
        "flat_keywords = [kw.strip() for sublist in keywords for kw in sublist]\n",
        "Counter(flat_keywords).most_common(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae4b1727",
      "metadata": {
        "id": "ae4b1727"
      },
      "source": [
        "The dataset is incomplete in some aspects. For instance, the rate column does not always contain the actual review rating. However, this information can be retrieved from the paper score column, which is similar to the score column but also includes a rating label.\n",
        "\n",
        "Additionally, we notice that many values are not unique. This information can be valuable for optimizing certain computations, as it may help reduce redundancy in the data processing."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "819bc035",
      "metadata": {
        "id": "819bc035"
      },
      "source": [
        "Let's visualize the total number of rejections and acceptances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dcc7c0b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "dcc7c0b6",
        "outputId": "0c55b67c-648d-489e-ee06-3ae1f6ba1291"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "paper_decision = df[\"paper_decision\"].value_counts(dropna=True)\n",
        "decision_label = [\"Reject\", \"Accept (Poster)\", \"Accept (Spotlight)\", \"Accept (Talk)\"]\n",
        "paper_decision.index = decision_label\n",
        "\n",
        "fig, ax = plt.subplots(1,1)\n",
        "sns.barplot(data=paper_decision, ax=ax)\n",
        "ax.set_xlabel(\"Decision\")\n",
        "ax.set_ylabel(\"Count\")\n",
        "ax.set_title(\"Decision outcomes\")\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e794cb97",
      "metadata": {
        "id": "e794cb97"
      },
      "source": [
        "Getting a paper accepted is a challenging task, especially since a paper can be rejected multiple times before it is eventually accepted.\n",
        "\n",
        "Based on the previous plot, we can estimate the probability of a paper being rejected or accepted simply computing the ratio. It is important to consider that the same paper may experience multiple rejections before ultimately being accepted. This of course will probably overshot the rejection percentage but in this analysis, we are going to consider each review as being done on an individual paper as at each \"iteration\", the paper can be considered different from the previous one because of changes made."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "12fff836",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12fff836",
        "outputId": "5e219375-fb4b-4fae-9d76-d56e58c942f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "paper_decision\n",
            "Decision:###Reject                69.316993\n",
            "Decision:###Accept (Poster)       23.733373\n",
            "Decision:###Accept (Spotlight)     4.782544\n",
            "Decision:###Accept (Talk)          2.167090\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print (df['paper_decision'].value_counts(normalize=True) * 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0d260ee",
      "metadata": {
        "id": "e0d260ee"
      },
      "source": [
        "Approximately 70% of the papers in the dataset have been rejected, which is quite a large proportion.\n",
        "\n",
        "One of the first questions that comes to my mind is whether there is a correlation between a paper's acceptance or rejection and its keywords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9869884c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9869884c",
        "outputId": "3f33ccdb-2626-4c1c-8d2a-73074bea234c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                     keyword  total  accepted  acceptance_rate\n",
            "0            batch selection      3         0         0.000000\n",
            "1           uncertain sample      3         0         0.000000\n",
            "2               acceleration     18         6        33.333333\n",
            "3                convergence     19        10        52.631579\n",
            "4                noisy label      7         0         0.000000\n",
            "...                      ...    ...       ...              ...\n",
            "4095             homogeneous      3         3       100.000000\n",
            "4096        provable defense      3         3       100.000000\n",
            "4097      convex relaxations      3         3       100.000000\n",
            "4098         knowledge bases      3         3       100.000000\n",
            "4099  data structures for qa      3         3       100.000000\n",
            "\n",
            "[4100 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# create a dictionary to count accepted and total papers for each keyword\n",
        "keyword_stats = defaultdict(lambda: {'accepted': 0, 'total': 0})\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    keywords = str(row['keyword']).replace(\"Keywords:###\", \"\")\n",
        "    decision = row['paper_decision']\n",
        "\n",
        "    if pd.notna(keywords):\n",
        "        for keyword in keywords.lower().split(','):\n",
        "            keyword = keyword.strip()\n",
        "            keyword_stats[keyword]['total'] += 1\n",
        "            if pd.notna(decision) and 'Decision:###Reject' not in decision:\n",
        "                keyword_stats[keyword]['accepted'] += 1\n",
        "\n",
        "# turn the stats into a dataframe\n",
        "# as it is much easier to manipulate after\n",
        "keyword_df = pd.DataFrame([\n",
        "    {'keyword': k,\n",
        "     'total': v['total'],\n",
        "     'accepted': v['accepted'],\n",
        "     'acceptance_rate': v['accepted'] / v['total'] * 100}\n",
        "    for k, v in keyword_stats.items()\n",
        "])\n",
        "\n",
        "print(keyword_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9270676",
      "metadata": {
        "id": "f9270676"
      },
      "source": [
        "Some keywords have a high acceptance rate (e.g., \"homogeneous,\" \"provable defense\"), while others are associated with papers that have never been accepted (e.g., \"batch selection,\" \"uncertain sample\").\n",
        "\n",
        "We can hypothesize that certain keywords may have very high acceptance rates, suggesting they correspond to topics the conference tends to favor. This could be the case for frequently occurring keywords, though it may also simply be a coincidence. On the other hand, popular keywords with low acceptance rates might point to highly competitive or saturated areas.\n",
        "\n",
        "Regardless, this information can guide our analysis. By focusing on papers with keywords that have a higher acceptance rate, we can potentially increase the likelihood of selecting papers with a higher probability of acceptance, while excluding those with keywords that are less likely to be accepted.\n",
        "\n",
        "To further explore this, we will also investigate any potential relationship between paper outcomes and keywords using a simple random forest model.\n",
        "\n",
        "The general idea of finding this type of correlation is also to drop most of the papers that at the end have not / might not be accepted in order to speed up computation for other ml models as we will see later (even a simple llm model might require a lot of time for a single input). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "BfA6LvvGGVL0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BfA6LvvGGVL0",
        "outputId": "9362fa04-44b9-4f9b-b9f8-06d5472ce2db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Classification report ===\n",
            "                                precision    recall  f1-score   support\n",
            "\n",
            "   Decision:###Accept (Poster)       1.00      0.86      0.92       319\n",
            "Decision:###Accept (Spotlight)       1.00      0.87      0.93        68\n",
            "     Decision:###Accept (Talk)       1.00      0.88      0.94        34\n",
            "            Decision:###Reject       0.90      1.00      0.95       920\n",
            "                        Reject       0.98      0.81      0.89       213\n",
            "\n",
            "                      accuracy                           0.94      1554\n",
            "                     macro avg       0.98      0.88      0.92      1554\n",
            "                  weighted avg       0.94      0.94      0.93      1554\n",
            "\n",
            "\n",
            "=== Top 20 most predictive keywords ===\n",
            "deep learning: 0.0106\n",
            "reinforcement learning: 0.0051\n",
            "representation learning: 0.0044\n",
            "natural language processing: 0.0035\n",
            "robustness: 0.0032\n",
            "interpretability: 0.0031\n",
            "meta-learning: 0.0031\n",
            "computer vision: 0.0029\n",
            "exploration: 0.0028\n",
            "imitation learning: 0.0028\n",
            "transfer learning: 0.0028\n",
            "knowledge graph embeddings: 0.0027\n",
            "generalization: 0.0026\n",
            "actor-critic: 0.0026\n",
            "incremental learning: 0.0025\n",
            "regularization: 0.0025\n",
            "compositionality: 0.0025\n",
            "action recognition: 0.0025\n",
            "domain adaptation: 0.0024\n",
            "neural networks: 0.0024\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = df.copy() # to be sure we don't modify the previous data frame\n",
        "\n",
        "# cleaning and prepare keywords\n",
        "df['keyword'] = df['keyword'].fillna('')\n",
        "df['clean_keywords'] = df['keyword'].apply(\n",
        "    lambda x: [kw.strip().lower() for kw in x.replace(\"Keywords:###\", \"\").split(',') if kw.strip()]\n",
        ")\n",
        "\n",
        "# obtain unique keywords\n",
        "all_keywords = [kw for kws in df['clean_keywords'] for kw in kws]\n",
        "unique_keywords = sorted(set(all_keywords))\n",
        "\n",
        "# transform into binary features\n",
        "mlb = MultiLabelBinarizer(classes=unique_keywords)\n",
        "X_keywords = mlb.fit_transform(df['clean_keywords'])\n",
        "\n",
        "# encode target\n",
        "df['paper_decision'] = df['paper_decision'].fillna('Reject')\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['paper_decision'])\n",
        "\n",
        "# split dataset for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_keywords, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# train random forest\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# evaluation and results\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"\\n=== Classification report ===\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "importances = model.feature_importances_\n",
        "keyword_importance = sorted(zip(mlb.classes_, importances), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"\\n=== Top 20 most predictive keywords ===\")\n",
        "for kw, score in keyword_importance[:20]:\n",
        "    print(f\"{kw}: {score:.4f}\")\n",
        "\n",
        "# a simple bar plot to visualize keyword importance\n",
        "top_keywords, scores = zip(*keyword_importance[:20])\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(top_keywords[::-1], scores[::-1])\n",
        "plt.xlabel(\"Importance Score\")\n",
        "plt.title(\"Top 20 Predictive Keywords\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dj8p3hlNG-Nc",
      "metadata": {
        "id": "dj8p3hlNG-Nc"
      },
      "source": [
        "We found that keywords like \"deep learning,\" \"reinforcement learning\" and \"representation learning\" have the highest importance within the model. This suggests that these tags either correlate with higher acceptance rates or exhibit a clear, consistent decision pattern (whether accepted or rejected).\n",
        "\n",
        "However, its important to note that a high importance score doesnt necessarily imply a direct correlation with acceptance. It simply means the keyword plays a significant role in the classification, regardless of whether it leans towards acceptance or rejection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "YNpixiYXHkdm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNpixiYXHkdm",
        "outputId": "45587f82-91e7-428c-fc77-b560655433a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                          keyword  importance  acceptance_rate\n",
            "0                   deep learning    0.010611        28.683036\n",
            "1          reinforcement learning    0.005089        30.681818\n",
            "2         representation learning    0.004383        21.782178\n",
            "3     natural language processing    0.003511        20.786517\n",
            "4                      robustness    0.003241        30.434783\n",
            "...                           ...         ...              ...\n",
            "4094             supperresolution    0.000000         0.000000\n",
            "4095         ternary quantization    0.000000         0.000000\n",
            "4096               text-to-speech    0.000000         0.000000\n",
            "4097               transformer-xh    0.000000       100.000000\n",
            "4098             weight averaging    0.000000         0.000000\n",
            "\n",
            "[4099 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "keyword_outcome_compare = keyword_df[[\"keyword\", \"acceptance_rate\"]]\n",
        "\n",
        "keywords, scores = zip(*keyword_importance)\n",
        "model_keywords_df = pd.DataFrame({\n",
        "    'keyword': keywords,\n",
        "    'importance': scores\n",
        "})\n",
        "\n",
        "comparison_df = pd.merge(model_keywords_df, keyword_outcome_compare, on=\"keyword\", how=\"left\")\n",
        "\n",
        "print(comparison_df)\n",
        "\n",
        "# multiply the model importance scores by 100\n",
        "comparison_df['importance'] = comparison_df['importance'] * 100\n",
        "\n",
        "# sort by importance for better visualization\n",
        "comparison_df = comparison_df.sort_values(by='importance', ascending=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mj5zIyOaNhPq",
      "metadata": {
        "id": "mj5zIyOaNhPq"
      },
      "source": [
        "What can be said about this result?\n",
        "\n",
        "We have compared two methods to assess the importance of keywords and their relationship with paper acceptance rates.\n",
        "\n",
        "## Statistical Approach:\n",
        "The first approach relies on a statistical method, which simply counts the occurrences of each keyword in the dataset and tracks how many times each keyword is associated with accepted papers. This method provides a quick way to assess the likelihood of a paper's acceptance based on the presence of certain keywords. However, the frequency of a keyword is a crucial factor here, as more frequent keywords are likely to appear in successful papers, giving this method an inherent bias toward high-frequency terms.\n",
        "\n",
        "## Machine Learning Approach:\n",
        "The second method leverages machine learning to assess the importance of each keyword in predicting the acceptance or rejection of papers. Here, too, the frequency of a keyword plays an important role in determining its importance in the model. Keywords with higher frequency are more likely to have more accurate predictions because they are present in more papers, while rarer keywords may have less statistical power due to limited data.\n",
        "\n",
        "## Conclusion:\n",
        "By combining both the statistical insights (frequency and acceptance rate) and the machine learning model's keyword importance, we can derive a more nuanced understanding of which keywords are likely to indicate successful papers. Frequently occurring, high-importance keywords in the model often correlate with higher acceptance rates. However, even keywords that appear less frequently but are deemed highly important by the model may still significantly contribute to a paper's likelihood of success."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f4e0216",
      "metadata": {
        "id": "1f4e0216"
      },
      "source": [
        "# Determining acceptance score\n",
        "\n",
        "The strategy involves focusing on papers whose keywords have a high acceptance rate (e.g.  80%) to better understand what factors contribute to paper acceptance.\n",
        "\n",
        "## Handling Multiple Keywords\n",
        "- Some papers may have multiple keywords, one with a high acceptance rate and another with a lower acceptance rate. We need to define a formula for the paper score considering both cases.\n",
        "\n",
        "- Assuming each keyword's acceptance is independent, we can compute the average acceptance rate for all keywords associated with a paper. If the average acceptance rate exceeds a given threshold (e.g., 80%), this would suggest a higher likelihood of acceptance for that paper. This allows us to handle cases where papers have mixed keywords in terms of acceptance rates.\n",
        "\n",
        "## Analyzing Reviews for Recurring Patterns\n",
        "Once we have identified the papers with keywords that have high acceptance rates, we can then dive deeper into their reviews. The aim is to identify recurring patterns, which may include:\n",
        "\n",
        "- Frequent phrases, these could indicate common strengths or weaknesses across accepted papers.\n",
        "\n",
        "- Sentiment and tone, positive or negative tones in the reviews may help correlate specific attributes with higher acceptance.\n",
        "\n",
        "- Review scores, are there particular sections that consistently receive higher or lower scores? These might point to areas that are particularly important for success.\n",
        "\n",
        "## Additional Considerations\n",
        "\n",
        "- Acceptance is not solely determined by keywords, it's important to keep in mind that other factors, beyond just the keywords, may play a significant role in the acceptance of a paper. For example, the paper's overall structure, the clarity of writing, novelty, technical depth, and contributions to the field could also be crucial.\n",
        "\n",
        "- Keyword importance is just one piece of the puzzle, while a high acceptance rate for certain keywords can guide us, it's essential to balance this with other aspects of the paper that contribute to its success. By analyzing the reviews and the overall paper content, we can gain a deeper understanding of what drives success in accepted papers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "314f5ca8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "314f5ca8",
        "outputId": "36ceac51-cc8f-4d36-f7a2-82fc5e4389e4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"unique_likely_papers[['title', 'avg_keyword_acceptance']]\",\n  \"rows\": 111,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 111,\n        \"samples\": [\n          \"Learning Nearly Decomposable Value Functions Via Communication Minimization | OpenReview\",\n          \"Analysis of Video Feature Learning in Two-Stream CNNs on the Example of Zebrafish Swim Bout Classification | OpenReview\",\n          \"Weakly Supervised Clustering by Exploiting Unique Class Count | OpenReview\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_keyword_acceptance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07927116109656036,\n        \"min\": 0.8026666666666668,\n        \"max\": 1.0,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          0.9,\n          0.8039911308203991,\n          0.8285714285714286\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-63e76a0f-3118-4d56-a9c4-3d43b546822a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>avg_keyword_acceptance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Learning deep graph matching with channel-inde...</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Graph inference learning for semi-supervised c...</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Evaluating The Search Phase of Neural Architec...</td>\n",
              "      <td>0.838542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>To Relieve Your Headache of Training an MRF, T...</td>\n",
              "      <td>0.811321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Weakly Supervised Clustering by Exploiting Uni...</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>Rotation-invariant clustering of functional ce...</td>\n",
              "      <td>0.857366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>Causal Discovery with Reinforcement Learning |...</td>\n",
              "      <td>0.826705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326</th>\n",
              "      <td>High Fidelity Speech Synthesis with Adversaria...</td>\n",
              "      <td>0.854167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329</th>\n",
              "      <td>Convolutional Conditional Neural Processes | O...</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>332</th>\n",
              "      <td>Gradient Descent Maximizes the Margin of Homog...</td>\n",
              "      <td>0.851852</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>111 rows  2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63e76a0f-3118-4d56-a9c4-3d43b546822a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-63e76a0f-3118-4d56-a9c4-3d43b546822a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-63e76a0f-3118-4d56-a9c4-3d43b546822a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7c3b3dd0-b372-4b48-8e17-d89adaa453da\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7c3b3dd0-b372-4b48-8e17-d89adaa453da')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7c3b3dd0-b372-4b48-8e17-d89adaa453da button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                 title  avg_keyword_acceptance\n",
              "0    Learning deep graph matching with channel-inde...                1.000000\n",
              "3    Graph inference learning for semi-supervised c...                1.000000\n",
              "6    Evaluating The Search Phase of Neural Architec...                0.838542\n",
              "9    To Relieve Your Headache of Training an MRF, T...                0.811321\n",
              "12   Weakly Supervised Clustering by Exploiting Uni...                0.833333\n",
              "..                                                 ...                     ...\n",
              "320  Rotation-invariant clustering of functional ce...                0.857366\n",
              "323  Causal Discovery with Reinforcement Learning |...                0.826705\n",
              "326  High Fidelity Speech Synthesis with Adversaria...                0.854167\n",
              "329  Convolutional Conditional Neural Processes | O...                0.833333\n",
              "332  Gradient Descent Maximizes the Margin of Homog...                0.851852\n",
              "\n",
              "[111 rows x 2 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keyword_probs = dict(zip(keyword_df['keyword'], keyword_df['acceptance_rate'] / 100))\n",
        "threshold = 0.8  # acceptance rate of a paper based on the avergae of the keywords probabilities\n",
        "likely_accepted_papers = []\n",
        "\n",
        "# iterate each paper\n",
        "for idx, row in df.iterrows():\n",
        "    keywords = str(row['keyword']).replace(\"Keywords:###\", \"\")\n",
        "\n",
        "    if pd.notna(keywords) and keywords.strip():\n",
        "        keyword_list = [kw.strip().lower() for kw in keywords.split(',')]\n",
        "\n",
        "        # take all proabilities of paper keywords\n",
        "        keyword_acceptances = [keyword_probs[kw] for kw in keyword_list if kw in keyword_probs]\n",
        "\n",
        "        if keyword_acceptances:\n",
        "            avg_acceptance = sum(keyword_acceptances) / len(keyword_acceptances)\n",
        "\n",
        "            if avg_acceptance >= threshold:\n",
        "                # paper likely to be accepted\n",
        "                # store also the average acceptance\n",
        "                paper_info = row.to_dict()\n",
        "                paper_info['avg_keyword_acceptance'] = avg_acceptance\n",
        "                likely_accepted_papers.append(paper_info)\n",
        "\n",
        "likely_accepted_df = pd.DataFrame(likely_accepted_papers)\n",
        "\n",
        "#printing of title papers\n",
        "unique_likely_papers = likely_accepted_df.drop_duplicates(subset=['title'], ignore_index=False)\n",
        "unique_likely_papers[['title', 'avg_keyword_acceptance']]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kx7_mnlFp7VE",
      "metadata": {
        "id": "kx7_mnlFp7VE"
      },
      "source": [
        "Here we will compute the final acceptance score that is given by the avergae keywords acceptance score and the model acceptance score.\\\n",
        "Given that I think both scores are important, the final score is a simple weighted average where each of the two scores have same importance that is, 50%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "rIWxkSSMPiEJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rIWxkSSMPiEJ",
        "outputId": "64402110-0d3e-4321-eae2-47e73a24a518"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"unique_likely_papers[['title', 'avg_keyword_acceptance', 'model_acceptance_score', 'final_acceptance_score']]\",\n  \"rows\": 38,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 38,\n        \"samples\": [\n          \"Disentanglement through Nonlinear ICA with General Incompressible-flow Networks (GIN) | OpenReview\",\n          \"Depth-Width Trade-offs for ReLU Networks via Sharkovsky*s Theorem | OpenReview\",\n          \"A Signal Propagation Perspective for Pruning Neural Networks at Initialization | OpenReview\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_keyword_acceptance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11121563458060169,\n        \"min\": 0.6631675944175944,\n        \"max\": 1.0,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          0.6654575892857143,\n          0.7719298245614036,\n          0.6713662790697674\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_acceptance_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.034245680910905726,\n        \"min\": 0.8648809001432132,\n        \"max\": 1.0,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          0.8711015323485506,\n          0.961103584215036,\n          0.9709442171690038\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"final_acceptance_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05975148349843038,\n        \"min\": 0.8006831395348837,\n        \"max\": 1.0,\n        \"num_unique_values\": 38,\n        \"samples\": [\n          0.8204185418541854,\n          0.8498364804599896,\n          0.8921248133310393\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1a608060-6c98-4cc2-9052-dca6a350c194\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>avg_keyword_acceptance</th>\n",
              "      <th>model_acceptance_score</th>\n",
              "      <th>final_acceptance_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Program Guided Agent | OpenReview</td>\n",
              "      <td>0.881138</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.880569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>InfoGraph: Unsupervised and Semi-supervised Gr...</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.971016</td>\n",
              "      <td>0.842651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>On Robustness of Neural Ordinary Differential ...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.971079</td>\n",
              "      <td>0.985540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Estimating Gradients for Discrete Random Varia...</td>\n",
              "      <td>0.879545</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.929773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>A Signal Propagation Perspective for Pruning N...</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.950916</td>\n",
              "      <td>0.892125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>WHITE NOISE ANALYSIS OF NEURAL NETWORKS | Open...</td>\n",
              "      <td>0.747888</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>0.843944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Online and stochastic optimization beyond Lips...</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.921725</td>\n",
              "      <td>0.856696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Encoding word order in complex embeddings | Op...</td>\n",
              "      <td>0.772727</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.886364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>DDSP: Differentiable Digital Signal Processing...</td>\n",
              "      <td>0.803991</td>\n",
              "      <td>0.920000</td>\n",
              "      <td>0.861996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Finite Depth and Width Corrections to the Neur...</td>\n",
              "      <td>0.755072</td>\n",
              "      <td>0.930792</td>\n",
              "      <td>0.842932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Meta-Learning without Memorization | OpenReview</td>\n",
              "      <td>0.687236</td>\n",
              "      <td>0.920000</td>\n",
              "      <td>0.803618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>How much Position Information Do Convolutional...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.922844</td>\n",
              "      <td>0.961422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Hamiltonian Generative Networks | OpenReview</td>\n",
              "      <td>0.816406</td>\n",
              "      <td>0.950346</td>\n",
              "      <td>0.883376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Estimating counterfactual treatment outcomes o...</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.970944</td>\n",
              "      <td>0.902139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Gradientless Descent: High-Dimensional Zeroth-...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Emergence of functional and structural propert...</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.942206</td>\n",
              "      <td>0.908603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Deep neuroethology of a virtual rodent | OpenR...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.960694</td>\n",
              "      <td>0.980347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Doubly Robust Bias Reduction in Infinite Horiz...</td>\n",
              "      <td>0.826705</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.903352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>Learning Compositional Koopman Operators for M...</td>\n",
              "      <td>0.722306</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>0.831153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>Simplified Action Decoder for Deep Multi-Agent...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.961291</td>\n",
              "      <td>0.980646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>Network Deconvolution | OpenReview</td>\n",
              "      <td>0.771930</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.875965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>Neural Symbolic Reader: Scalable Integration o...</td>\n",
              "      <td>0.742540</td>\n",
              "      <td>0.961104</td>\n",
              "      <td>0.851822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>Dream to Control: Learning Behaviors by Latent...</td>\n",
              "      <td>0.663168</td>\n",
              "      <td>0.970000</td>\n",
              "      <td>0.816584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>A Probabilistic Formulation of Unsupervised Te...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.971196</td>\n",
              "      <td>0.985598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>Model Based Reinforcement Learning for Atari |...</td>\n",
              "      <td>0.701705</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.825852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>Stable Rank Normalization for Improved General...</td>\n",
              "      <td>0.792079</td>\n",
              "      <td>0.880999</td>\n",
              "      <td>0.836539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>Neural Tangents: Fast and Easy Infinite Neural...</td>\n",
              "      <td>0.680254</td>\n",
              "      <td>0.941497</td>\n",
              "      <td>0.810875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>The intriguing role of module criticality in t...</td>\n",
              "      <td>0.762277</td>\n",
              "      <td>0.930000</td>\n",
              "      <td>0.846138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>Harnessing the Power of Infinitely Wide Deep N...</td>\n",
              "      <td>0.689907</td>\n",
              "      <td>0.930000</td>\n",
              "      <td>0.809953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>What Can Neural Networks Reason About? | OpenR...</td>\n",
              "      <td>0.671366</td>\n",
              "      <td>0.930000</td>\n",
              "      <td>0.800683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>Learning from Rules Generalizing Labeled Exemp...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.920722</td>\n",
              "      <td>0.960361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Compression based bound for non-compressed net...</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.864881</td>\n",
              "      <td>0.856683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>At Stability*s Edge: How to Adjust Hyperparame...</td>\n",
              "      <td>0.709213</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.829607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>Disentanglement through Nonlinear ICA with Gen...</td>\n",
              "      <td>0.770837</td>\n",
              "      <td>0.870000</td>\n",
              "      <td>0.820419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>Deep Learning For Symbolic Mathematics | OpenR...</td>\n",
              "      <td>0.665458</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>0.802729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>Unbiased Contrastive Divergence Algorithm for ...</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.942226</td>\n",
              "      <td>0.921113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>Depth-Width Trade-offs for ReLU Networks via S...</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.871102</td>\n",
              "      <td>0.849836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>Reconstructing continuous distributions of 3D ...</td>\n",
              "      <td>0.691456</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.825728</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a608060-6c98-4cc2-9052-dca6a350c194')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1a608060-6c98-4cc2-9052-dca6a350c194 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1a608060-6c98-4cc2-9052-dca6a350c194');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f2fd64a3-f5fd-479c-bb14-2d93cacf0224\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f2fd64a3-f5fd-479c-bb14-2d93cacf0224')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f2fd64a3-f5fd-479c-bb14-2d93cacf0224 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                 title  \\\n",
              "0                    Program Guided Agent | OpenReview   \n",
              "3    InfoGraph: Unsupervised and Semi-supervised Gr...   \n",
              "6    On Robustness of Neural Ordinary Differential ...   \n",
              "9    Estimating Gradients for Discrete Random Varia...   \n",
              "12   A Signal Propagation Perspective for Pruning N...   \n",
              "15   WHITE NOISE ANALYSIS OF NEURAL NETWORKS | Open...   \n",
              "19   Online and stochastic optimization beyond Lips...   \n",
              "22   Encoding word order in complex embeddings | Op...   \n",
              "26   DDSP: Differentiable Digital Signal Processing...   \n",
              "29   Finite Depth and Width Corrections to the Neur...   \n",
              "32     Meta-Learning without Memorization | OpenReview   \n",
              "35   How much Position Information Do Convolutional...   \n",
              "38        Hamiltonian Generative Networks | OpenReview   \n",
              "41   Estimating counterfactual treatment outcomes o...   \n",
              "44   Gradientless Descent: High-Dimensional Zeroth-...   \n",
              "47   Emergence of functional and structural propert...   \n",
              "50   Deep neuroethology of a virtual rodent | OpenR...   \n",
              "53   Doubly Robust Bias Reduction in Infinite Horiz...   \n",
              "56   Learning Compositional Koopman Operators for M...   \n",
              "60   Simplified Action Decoder for Deep Multi-Agent...   \n",
              "63                  Network Deconvolution | OpenReview   \n",
              "66   Neural Symbolic Reader: Scalable Integration o...   \n",
              "69   Dream to Control: Learning Behaviors by Latent...   \n",
              "73   A Probabilistic Formulation of Unsupervised Te...   \n",
              "76   Model Based Reinforcement Learning for Atari |...   \n",
              "79   Stable Rank Normalization for Improved General...   \n",
              "82   Neural Tangents: Fast and Easy Infinite Neural...   \n",
              "85   The intriguing role of module criticality in t...   \n",
              "88   Harnessing the Power of Infinitely Wide Deep N...   \n",
              "91   What Can Neural Networks Reason About? | OpenR...   \n",
              "94   Learning from Rules Generalizing Labeled Exemp...   \n",
              "97   Compression based bound for non-compressed net...   \n",
              "100  At Stability*s Edge: How to Adjust Hyperparame...   \n",
              "103  Disentanglement through Nonlinear ICA with Gen...   \n",
              "106  Deep Learning For Symbolic Mathematics | OpenR...   \n",
              "109  Unbiased Contrastive Divergence Algorithm for ...   \n",
              "112  Depth-Width Trade-offs for ReLU Networks via S...   \n",
              "114  Reconstructing continuous distributions of 3D ...   \n",
              "\n",
              "     avg_keyword_acceptance  model_acceptance_score  final_acceptance_score  \n",
              "0                  0.881138                0.880000                0.880569  \n",
              "3                  0.714286                0.971016                0.842651  \n",
              "6                  1.000000                0.971079                0.985540  \n",
              "9                  0.879545                0.980000                0.929773  \n",
              "12                 0.833333                0.950916                0.892125  \n",
              "15                 0.747888                0.940000                0.843944  \n",
              "19                 0.791667                0.921725                0.856696  \n",
              "22                 0.772727                1.000000                0.886364  \n",
              "26                 0.803991                0.920000                0.861996  \n",
              "29                 0.755072                0.930792                0.842932  \n",
              "32                 0.687236                0.920000                0.803618  \n",
              "35                 1.000000                0.922844                0.961422  \n",
              "38                 0.816406                0.950346                0.883376  \n",
              "41                 0.833333                0.970944                0.902139  \n",
              "44                 1.000000                1.000000                1.000000  \n",
              "47                 0.875000                0.942206                0.908603  \n",
              "50                 1.000000                0.960694                0.980347  \n",
              "53                 0.826705                0.980000                0.903352  \n",
              "56                 0.722306                0.940000                0.831153  \n",
              "60                 1.000000                0.961291                0.980646  \n",
              "63                 0.771930                0.980000                0.875965  \n",
              "66                 0.742540                0.961104                0.851822  \n",
              "69                 0.663168                0.970000                0.816584  \n",
              "73                 1.000000                0.971196                0.985598  \n",
              "76                 0.701705                0.950000                0.825852  \n",
              "79                 0.792079                0.880999                0.836539  \n",
              "82                 0.680254                0.941497                0.810875  \n",
              "85                 0.762277                0.930000                0.846138  \n",
              "88                 0.689907                0.930000                0.809953  \n",
              "91                 0.671366                0.930000                0.800683  \n",
              "94                 1.000000                0.920722                0.960361  \n",
              "97                 0.848485                0.864881                0.856683  \n",
              "100                0.709213                0.950000                0.829607  \n",
              "103                0.770837                0.870000                0.820419  \n",
              "106                0.665458                0.940000                0.802729  \n",
              "109                0.900000                0.942226                0.921113  \n",
              "112                0.828571                0.871102                0.849836  \n",
              "114                0.691456                0.960000                0.825728  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "keyword_probs = dict(zip(keyword_df['keyword'], keyword_df['acceptance_rate'] / 100))\n",
        "\n",
        "threshold = 0.8  # acceptance rate threshold (this can be modified based on the needs)\n",
        "likely_accepted_papers = []\n",
        "\n",
        "# iterate each paper to determine the score and filter out\n",
        "# the ones that are below the threshold\n",
        "for idx, row in df.iterrows():\n",
        "    keywords = str(row['keyword']).replace(\"Keywords:###\", \"\")\n",
        "\n",
        "    if pd.notna(keywords) and keywords.strip():\n",
        "        keyword_list = [kw.strip().lower() for kw in keywords.split(',')]\n",
        "\n",
        "        keyword_acceptances = [keyword_probs[kw] for kw in keyword_list if kw in keyword_probs]\n",
        "\n",
        "        if keyword_acceptances:\n",
        "            # the \"statistical way\", basedon keywords frequencies\n",
        "            avg_keyword_acceptance = sum(keyword_acceptances) / len(keyword_acceptances)\n",
        "\n",
        "            # the \"ml way\", using the trained random forest\n",
        "            features = mlb.transform([keyword_list])\n",
        "            model_acceptance_score = model.predict_proba(features)[:, 1]\n",
        "            model_acceptance_score = model_acceptance_score[0]\n",
        "\n",
        "            # combine both scores\n",
        "            final_acceptance_score = (avg_keyword_acceptance + model_acceptance_score) / 2 # both have same weigth\n",
        "            # in the case the ml model shoudl have more weight, just change the ratio\n",
        "\n",
        "            # if above threshold, likely to be accepted\n",
        "            if final_acceptance_score >= threshold:\n",
        "                paper_info = row.to_dict()\n",
        "                paper_info['avg_keyword_acceptance'] = avg_keyword_acceptance\n",
        "                paper_info['model_acceptance_score'] = model_acceptance_score\n",
        "                paper_info['final_acceptance_score'] = final_acceptance_score\n",
        "                likely_accepted_papers.append(paper_info)\n",
        "\n",
        "likely_accepted_df = pd.DataFrame(likely_accepted_papers)\n",
        "\n",
        "# drop duplicates based on paper title to displat relevant columns\n",
        "unique_likely_papers = likely_accepted_df.drop_duplicates(subset=['title'], ignore_index=False)\n",
        "unique_likely_papers[['title', 'avg_keyword_acceptance', 'model_acceptance_score', 'final_acceptance_score']]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a21fd2f",
      "metadata": {
        "id": "2a21fd2f"
      },
      "source": [
        "By setting a threshold of 80% for the acceptance rate of keywords, we narrow down the dataset to 114 papers. This selection is based on the premise that papers with keywords having high acceptance rates are more likely to be successful. However, it's important to highlight a few considerations:\n",
        "\n",
        "- By averaging the acceptance rates of all keywords associated with a paper, we may end up with papers that have a lower average keyword acceptance rate compared to others. This discrepancy arises because of the frequency of specific keywords in the paper. A paper with several high-acceptance keywords may still have a lower overall average if it contains other low-acceptance keywords.\n",
        "\n",
        "- To mitigate this, we integrate the score given by the trained model. This model score helps to balance the final score, offering a more comprehensive perspective on the paper's potential for acceptance beyond just keyword frequency.\n",
        "\n",
        "\n",
        "An interesting observation is that the dataset, which includes non-unique paper names (due to multiple reviews per paper), provides a \"review history\" for each paper. This enables us to explore several dimensions:\n",
        "\n",
        "- By grouping reviews by paper title, we can track how the sentiment towards a paper changes across different review instances. This helps in understanding whether the overall perception of the paper evolves positively or negatively as revisions are made.\n",
        "\n",
        "- Some papers may start with weaker reviews but show improvement as revisions are made. This analysis allows us to see if there are key changes that contributed to better acceptance.\n",
        "\n",
        "- By analyzing the review comments and their sentiment, we can attempt to identify which types of feedback (positive or negative) are most correlated with a paper's acceptance. This could reveal common strengths or weaknesses pointed out by reviewers that impact the acceptance decision.\n",
        "\n",
        "Given the complexity of the task, we will focus only on comuting the sentiment and the key aspects of each review such that it will be possible to understand why a certain paper has been accepted in the end and which modification have been adopted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7da97eed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7da97eed",
        "outputId": "bf2860bf-2e3f-4a93-c22e-39c347cfcc61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Paper: A Probabilistic Formulation of Unsupervised Text Style Transfer | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "73       Rating:###8: Accept   NaN   \n",
            "74  Rating:###6: Weak Accept   NaN   \n",
            "75  Rating:###6: Weak Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "73  Review:###Summary: This paper introduces a pro...  \n",
            "74  Review:###In this paper, the authors propose a...  \n",
            "75   The main contribution of this paper is a prin...  \n",
            "\n",
            "Paper: A Signal Propagation Perspective for Pruning Neural Networks at Initialization | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "12  Rating:###6: Weak Accept   NaN   \n",
            "13       Rating:###8: Accept   NaN   \n",
            "14  Rating:###3: Weak Reject   NaN   \n",
            "\n",
            "                                               review  \n",
            "12  Review:###In this paper, the authors studied a...  \n",
            "13   This paper analyzes how signals propagate thr...  \n",
            "14  Review:###The paper introduces a signal propag...  \n",
            "\n",
            "Paper: At Stability*s Edge: How to Adjust Hyperparameters to Preserve Minima Selection in Asynchronous Training of Neural Networks? | OpenReview\n",
            "                  paper_score  rate  \\\n",
            "100       Rating:###8: Accept   NaN   \n",
            "101  Rating:###6: Weak Accept   NaN   \n",
            "102       Rating:###8: Accept   NaN   \n",
            "\n",
            "                                                review  \n",
            "100  Review:###This paper studies how asynchrony af...  \n",
            "101  Review:###The authors introduce a theoretical ...  \n",
            "102  Review:###The authors model A-SGD as a dynamic...  \n",
            "\n",
            "Paper: Compression based bound for non-compressed network: unified generalization error analysis of large compressible deep neural network | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "97  Rating:###6: Weak Accept   NaN   \n",
            "98       Rating:###8: Accept   NaN   \n",
            "99  Rating:###6: Weak Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "97  Review:###This paper obtains a compression-bas...  \n",
            "98   The paper presents novel theoretical results ...  \n",
            "99  Review:###This paper provides generalization b...  \n",
            "\n",
            "Paper: DDSP: Differentiable Digital Signal Processing | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "26       Rating:###8: Accept   NaN   \n",
            "27  Rating:###6: Weak Accept   NaN   \n",
            "28       Rating:###8: Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "26  Review:###This very nice paper tackles the int...  \n",
            "27  Review:###This paper presents a model for audi...  \n",
            "28  Review:###This paper develops a framework for ...  \n",
            "\n",
            "Paper: Deep Learning For Symbolic Mathematics | OpenReview\n",
            "                  paper_score  rate  \\\n",
            "106       Rating:###8: Accept   NaN   \n",
            "107       Rating:###8: Accept   NaN   \n",
            "108  Rating:###6: Weak Accept   NaN   \n",
            "\n",
            "                                                review  \n",
            "106  Review:###In this paper, the authors propose a...  \n",
            "107  Review:###The authors use a Transformer neural...  \n",
            "108   It is rather interesting for a humble academi...  \n",
            "\n",
            "Paper: Deep neuroethology of a virtual rodent | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "50  Rating:###6: Weak Accept   NaN   \n",
            "51  Rating:###6: Weak Accept   NaN   \n",
            "52       Rating:###8: Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "50  Review:###This is a fascinating paper that use...  \n",
            "51   =============================== Update after ...  \n",
            "52  Review:###The authors use a virtual rodent to ...  \n",
            "\n",
            "Paper: Depth-Width Trade-offs for ReLU Networks via Sharkovsky*s Theorem | OpenReview\n",
            "             paper_score  rate  \\\n",
            "112  Rating:###8: Accept   NaN   \n",
            "113  Rating:###8: Accept   NaN   \n",
            "\n",
            "                                                review  \n",
            "112  Review:###In tackling a curious construction b...  \n",
            "113  Review:###The paper studies how the expressive...  \n",
            "\n",
            "Paper: Disentanglement through Nonlinear ICA with General Incompressible-flow Networks (GIN) | OpenReview\n",
            "                  paper_score  rate  \\\n",
            "103       Rating:###8: Accept   NaN   \n",
            "104  Rating:###6: Weak Accept   NaN   \n",
            "105  Rating:###6: Weak Accept   NaN   \n",
            "\n",
            "                                                review  \n",
            "103   This paper extends recent work by Khemakhem e...  \n",
            "104  Review:###Based on a recent work on identifyin...  \n",
            "105  Review:###This paper builds upon the recent th...  \n",
            "\n",
            "Paper: Doubly Robust Bias Reduction in Infinite Horizon Off-Policy Estimation | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "53  Rating:###6: Weak Accept   NaN   \n",
            "54       Rating:###8: Accept   NaN   \n",
            "55       Rating:###8: Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "53  Review:###This paper proposes a new algorithm ...  \n",
            "54  Review:###Comments : This paper provides an ap...  \n",
            "55  Review:###*Synopsis*: This paper provides a ne...  \n",
            "\n",
            "Paper: Dream to Control: Learning Behaviors by Latent Imagination | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "69       Rating:###8: Accept   NaN   \n",
            "70  Rating:###6: Weak Accept   NaN   \n",
            "71  Rating:###6: Weak Accept   NaN   \n",
            "72       Rating:###8: Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "69  Review:###This paper presents a world model-ba...  \n",
            "70  Review:###This paper introduced a latent space...  \n",
            "71  Review:###Paper summary. The paper proposes Dr...  \n",
            "72  Review:###This work is clearly the work of a l...  \n",
            "\n",
            "Paper: Emergence of functional and structural properties of the head direction system by optimization of recurrent neural networks | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "47  Rating:###6: Weak Accept   NaN   \n",
            "48       Rating:###8: Accept   NaN   \n",
            "49  Rating:###6: Weak Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "47  Review:##### Overview This paper studies wheth...  \n",
            "48   This paper examines head direction representa...  \n",
            "49   The authors train RNNs to integrate motion cu...  \n",
            "\n",
            "Paper: Encoding word order in complex embeddings | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "22       Rating:###8: Accept   NaN   \n",
            "23  Rating:###6: Weak Accept   NaN   \n",
            "24       Rating:###8: Accept   NaN   \n",
            "25  Rating:###6: Weak Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "22   This paper makes present an original way to e...  \n",
            "23  Review:###### Problem and Previous Research Th...  \n",
            "24  Review:###This paper proposes to learn positio...  \n",
            "25  Review:###### Summary The authors present a *n...  \n",
            "\n",
            "Paper: Estimating Gradients for Discrete Random Variables by Sampling without Replacement | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "9   Rating:###6: Weak Accept   NaN   \n",
            "10  Rating:###6: Weak Accept   NaN   \n",
            "11       Rating:###8: Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "9    Summary: This paper introduces an gradient es...  \n",
            "10  Review:###Summary: In this paper, an unbiased ...  \n",
            "11  Review:###Edited after rebuttal: I*m satisfied...  \n",
            "\n",
            "Paper: Estimating counterfactual treatment outcomes over time through adversarially balanced representations | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "41       Rating:###8: Accept   NaN   \n",
            "42  Rating:###6: Weak Accept   NaN   \n",
            "43  Rating:###6: Weak Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "41  Review:###This work addresses the problem of c...  \n",
            "42  Review:###The paper introduces Counterfactual ...  \n",
            "43  Review:###The paper adapts domain adversarial ...  \n",
            "\n",
            "Paper: Finite Depth and Width Corrections to the Neural Tangent Kernel | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "29  Rating:###6: Weak Accept   NaN   \n",
            "30       Rating:###8: Accept   NaN   \n",
            "31       Rating:###8: Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "29   This paper studies the finite depth and width...  \n",
            "30  Review:###The paper investigates a novel infin...  \n",
            "31   This is an important contribution to understa...  \n",
            "\n",
            "Paper: Gradientless Descent: High-Dimensional Zeroth-Order Optimization | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "44  Rating:###6: Weak Accept   NaN   \n",
            "45       Rating:###8: Accept   NaN   \n",
            "46  Rating:###6: Weak Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "44  Review:###Update after rebuttal: I found the r...  \n",
            "45  Review:###** Summary The paper proposes a nove...  \n",
            "46  Review:###This paper proposes stable GradientL...  \n",
            "\n",
            "Paper: Hamiltonian Generative Networks | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "38       Rating:###8: Accept   NaN   \n",
            "39  Rating:###6: Weak Accept   NaN   \n",
            "40  Rating:###6: Weak Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "38  Review:###The paper introduces a novel way of ...  \n",
            "39  Review:###Summary: The authors present a metho...  \n",
            "40  Review:###The paper proposes two ideas: 1) Ham...  \n",
            "\n",
            "Paper: Harnessing the Power of Infinitely Wide Deep Nets on Small-data Tasks | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "88       Rating:###8: Accept   NaN   \n",
            "89  Rating:###6: Weak Accept   NaN   \n",
            "90       Rating:###8: Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "88   This paper conducts very interesting and mean...  \n",
            "89  Review:###This paper evaluates the empirical p...  \n",
            "90  Review:###[Summary] This paper performs an ext...  \n",
            "\n",
            "Paper: How much Position Information Do Convolutional Neural Networks Encode? | OpenReview\n",
            "            paper_score  rate  \\\n",
            "35  Rating:###8: Accept   NaN   \n",
            "36  Rating:###8: Accept   NaN   \n",
            "37  Rating:###8: Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "35  Review:###This paper studies whether and how p...  \n",
            "36  Review:###This paper studied the problem of th...  \n",
            "37  Review:###The paper investigates to what degre...  \n",
            "\n",
            "Paper: InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization | OpenReview\n",
            "                paper_score  rate  \\\n",
            "3  Rating:###6: Weak Accept   NaN   \n",
            "4  Rating:###6: Weak Accept   NaN   \n",
            "5  Rating:###6: Weak Accept   NaN   \n",
            "\n",
            "                                              review  \n",
            "3  Review:###The paper presents a new graph repre...  \n",
            "4  Review:###The paper presents an unsupervised m...  \n",
            "5  Review:###In this paper, the authors propose a...  \n",
            "\n",
            "Paper: Learning Compositional Koopman Operators for Model-Based Control | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "56  Rating:###6: Weak Accept   NaN   \n",
            "57  Rating:###6: Weak Accept   NaN   \n",
            "58  Rating:###6: Weak Accept   NaN   \n",
            "59       Rating:###8: Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "56  Review:###The paper proposes a novel method fo...  \n",
            "57  Review:###The paper is well written and the pr...  \n",
            "58  Review:###This paper proposes to learn composi...  \n",
            "59  Review:###This paper introduces an approach to...  \n",
            "\n",
            "Paper: Learning from Rules Generalizing Labeled Exemplars | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "94  Rating:###6: Weak Accept   NaN   \n",
            "95       Rating:###8: Accept   NaN   \n",
            "96  Rating:###6: Weak Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "94  Review:###The paper addresses the problem that...  \n",
            "95  Review:###This paper proposes a novel semi-sup...  \n",
            "96  Review:###In case of a lack of labeled data, h...  \n",
            "\n",
            "Paper: Meta-Learning without Memorization | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "32       Rating:###8: Accept   NaN   \n",
            "33  Rating:###6: Weak Accept   NaN   \n",
            "34       Rating:###8: Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "32  Review:###This paper analyses a pitfall of cur...  \n",
            "33  Review:###Summary: In this paper, the authors ...  \n",
            "34  Review:#######################################...  \n",
            "\n",
            "Paper: Model Based Reinforcement Learning for Atari | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "76  Rating:###6: Weak Accept   NaN   \n",
            "77       Rating:###8: Accept   NaN   \n",
            "78  Rating:###6: Weak Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "76  Review:###The paper addresses sample-efficient...  \n",
            "77  Review:###This paper covers the authors appro...  \n",
            "78   Summary This paper proposes a model-based rei...  \n",
            "\n",
            "Paper: Network Deconvolution | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "63  Rating:###6: Weak Accept   NaN   \n",
            "64       Rating:###8: Accept   NaN   \n",
            "65       Rating:###8: Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "63  Review:###This paper addresses the correlation...  \n",
            "64  Review:###This paper proposes an operation for...  \n",
            "65  Review:###This paper proposes *network deconvo...  \n",
            "\n",
            "Paper: Neural Symbolic Reader: Scalable Integration of Distributed and Symbolic Representations for Reading Comprehension | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "66  Rating:###6: Weak Accept   NaN   \n",
            "67  Rating:###6: Weak Accept   NaN   \n",
            "68       Rating:###8: Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "66  Review:###-- define cascade errors when you fi...  \n",
            "67  Review:###This paper discusses an extended DSL...  \n",
            "68   This paper presents a semantic parser that op...  \n",
            "\n",
            "Paper: Neural Tangents: Fast and Easy Infinite Neural Networks in Python | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "82  Rating:###3: Weak Reject   NaN   \n",
            "83       Rating:###8: Accept   NaN   \n",
            "84  Rating:###6: Weak Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "82  Review:###Summary: A Jax based neural tangents...  \n",
            "83  Review:###POST-REBUTTAL COMMENTS I appreciate ...  \n",
            "84  Review:###This work develops a library for wor...  \n",
            "\n",
            "Paper: On Robustness of Neural Ordinary Differential Equations | OpenReview\n",
            "                paper_score  rate  \\\n",
            "6  Rating:###6: Weak Accept   NaN   \n",
            "7       Rating:###8: Accept   NaN   \n",
            "8  Rating:###6: Weak Accept   NaN   \n",
            "\n",
            "                                              review  \n",
            "6  Review:###This paper investigates the robustne...  \n",
            "7  Review:###The paper is concerned with neural O...  \n",
            "8   This paper studied the robustness of neural O...  \n",
            "\n",
            "Paper: Online and stochastic optimization beyond Lipschitz continuity: A Riemannian approach | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "19       Rating:###8: Accept   NaN   \n",
            "20       Rating:###8: Accept   NaN   \n",
            "21  Rating:###6: Weak Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "19  Review:###The paper establishes optimal regret...  \n",
            "20  Review:###Summary: The paper generalizes regre...  \n",
            "21  Review:###This paper investigates online and s...  \n",
            "\n",
            "Paper: Program Guided Agent | OpenReview\n",
            "                paper_score  rate  \\\n",
            "0       Rating:###8: Accept   NaN   \n",
            "1  Rating:###6: Weak Accept   NaN   \n",
            "2       Rating:###8: Accept   NaN   \n",
            "\n",
            "                                              review  \n",
            "0  Review:###This paper provides a method for ins...  \n",
            "1  Review:###This paper presents a reinforcement ...  \n",
            "2  Review:###Update: I thank the reviewers for th...  \n",
            "\n",
            "Paper: Reconstructing continuous distributions of 3D protein structure from cryo-EM images | OpenReview\n",
            "                  paper_score  rate  \\\n",
            "114  Rating:###6: Weak Accept   NaN   \n",
            "115       Rating:###8: Accept   NaN   \n",
            "116       Rating:###8: Accept   NaN   \n",
            "\n",
            "                                                review  \n",
            "114  Review:###- The authors proposed a novel metho...  \n",
            "115  Review:###~The authors build a new method to r...  \n",
            "116  Review:###The authors introduce cryoDRGN, a VA...  \n",
            "\n",
            "Paper: Simplified Action Decoder for Deep Multi-Agent Reinforcement Learning | OpenReview\n",
            "            paper_score  rate  \\\n",
            "60  Rating:###8: Accept   NaN   \n",
            "61  Rating:###8: Accept   NaN   \n",
            "62  Rating:###8: Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "60  Review:###The paper presents SAD (Simplified A...  \n",
            "61  Review:###The paper examines the problem of ep...  \n",
            "62  Review:###This paper introduces a novel exploi...  \n",
            "\n",
            "Paper: Stable Rank Normalization for Improved Generalization in Neural Networks and GANs | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "79  Rating:###6: Weak Accept   NaN   \n",
            "80       Rating:###8: Accept   NaN   \n",
            "81       Rating:###8: Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "79   This paper proposes normalizing the stable ra...  \n",
            "80   Stable Rank Normalization for Improved Genera...  \n",
            "81  Review:###While spectral normalization is ofte...  \n",
            "\n",
            "Paper: The intriguing role of module criticality in the generalization of deep networks | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "85  Rating:###6: Weak Accept   NaN   \n",
            "86       Rating:###8: Accept   NaN   \n",
            "87  Rating:###6: Weak Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "85  Review:###The paper introduces concept of *mod...  \n",
            "86  Review:###This paper introduces a new way to r...  \n",
            "87  Review:###The paper builds upon the *module cr...  \n",
            "\n",
            "Paper: Unbiased Contrastive Divergence Algorithm for Training Energy-Based Latent Variable Models | OpenReview\n",
            "                  paper_score  rate  \\\n",
            "109  Rating:###6: Weak Accept   NaN   \n",
            "110       Rating:###8: Accept   NaN   \n",
            "111       Rating:###8: Accept   NaN   \n",
            "\n",
            "                                                review  \n",
            "109  Review:###Based on recent progress in unbiased...  \n",
            "110  Review:###The paper introduces an efficient, u...  \n",
            "111  Review:###The paper proposes an algorithmic im...  \n",
            "\n",
            "Paper: WHITE NOISE ANALYSIS OF NEURAL NETWORKS | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "15  Rating:###6: Weak Accept   NaN   \n",
            "16  Rating:###6: Weak Accept   NaN   \n",
            "17       Rating:###8: Accept   NaN   \n",
            "18  Rating:###3: Weak Reject   NaN   \n",
            "\n",
            "                                               review  \n",
            "15   This work inspects the bias existing in the n...  \n",
            "16  Review:###Summary: This paper introduces two t...  \n",
            "17  Review:###This is an interesting paper that us...  \n",
            "18   This paper uses classification images and spi...  \n",
            "\n",
            "Paper: What Can Neural Networks Reason About? | OpenReview\n",
            "                 paper_score  rate  \\\n",
            "91       Rating:###8: Accept   NaN   \n",
            "92  Rating:###6: Weak Accept   NaN   \n",
            "93       Rating:###8: Accept   NaN   \n",
            "\n",
            "                                               review  \n",
            "91  Review:###This paper presents a framework, dub...  \n",
            "92  Review:###This work seeks theoretical and empi...  \n",
            "93  Review:###The paper proposes a measure of clas...  \n"
          ]
        }
      ],
      "source": [
        "for title, group in likely_accepted_df.groupby('title'):\n",
        "    print(f\"\\nPaper: {title}\")\n",
        "    print(group[['paper_score', 'rate', 'review']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gwXufNOcXTuD",
      "metadata": {
        "id": "gwXufNOcXTuD"
      },
      "source": [
        "The next step in our analysis is to extract key aspects from the reviews while also determining whether the comments are positive or negative. By doing this, we will gain a clearer understanding of the feedback associated with each paper, allowing us to identify if the review praised the paper or if there were specific issues that led to the rejection.\n",
        "Steps Involved:\n",
        "\n",
        "- We will extract key aspects of each review, focusing on recurring phrases, comments, and feedback that highlight the strengths or weaknesses of the paper.\n",
        "\n",
        "- Sentiment analysis will be performed to categorize each review as positive or negative. This helps us immediately understand if the feedback was supportive or pointed out issues that could lead to rejection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5573d6b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554,
          "referenced_widgets": [
            "d92de0301331439aa8a754cac17f8231",
            "362c0fa9d7c048c7a4ed09bc7ab72023",
            "89e61b9d77094bcea0883f88a2063198",
            "521f564ec40d4f1db181a0d73f3bf600",
            "273c0dfeb3ed4343ac634207ca574ae7",
            "704efced50754c5d9b9d33253ad98647",
            "880cc986e20544f3bb3f3e59d409dfec",
            "da840982fbdb4df1ae67fc4bade0f598",
            "faf31c079431450ea07d48ca8eb7457e",
            "4acdc37965ad4208b39c206bc664caad",
            "0d28e5778bfc44a0a8752af881721c42",
            "8cd7847f2180479ca924203689de1303",
            "2fa7e7ab743c4fcba8cd3fef36be6fc0",
            "a91e3bbe7f734213ac864509c3506249",
            "423fb8d60a8b4de3bc2aeeb986ada6af",
            "168a0c4cf5244bacab7c6fba9bb19568",
            "142d99c05fab474fb6bc865c60b4e386",
            "84da9ab8fb8e499992a3620513ea331a",
            "00dd5b7a42da4121bfa7cb546e06a3af",
            "044f63def03a47ce9e278d9f72a70abb",
            "330e09be8a9643c5a2f62a2e1d273234",
            "88d0776599ef4f2ca791aa58ce005411",
            "5656af2ca4c3427b805e34ec7b2d756e",
            "cfec6489bc3a44d48ccd02df4d1d3390",
            "cabd191380774056a9b4704035a0ec38",
            "e7ebe848567940f3a47a04858eda28dd",
            "4283422cbb4c44fc8a4f57152826f746",
            "e6ece860fff54ecaacc17e8835d1a6c6",
            "5e5c7fecb10547669ddc9045680a9c82",
            "40eef96ef8d042898ae0ab178a0c2942",
            "e1ad9cb9e601490ebd9e83adb96e21b4",
            "1f91172173fa4cf99fbb179c133abdc9",
            "e9de5201452a4e55b5ee6c21fa1e4084",
            "003fdc9c912f4efebd0b24d9b5584017",
            "1994b3246d0c4e2c96bbf579ac0b2add",
            "06ef576ba5054d9faaf64cf5564b89f2",
            "ceaed24ce67d4aec857ccaa14c354a56",
            "c4d7104dfab14dbb9a3884af87f80df9",
            "c4c0b4bd04db4c10a7a1d6648bcb04b6",
            "8f3cd8234ac946679e13d001ec6d13c1",
            "6a66b684891d4fd5a415a9dcb1e5c81a",
            "80a5a93288ed4c2e84ce3763e714a8bc",
            "5661ac17164d45c0b96ba6981e2fdea2",
            "02d1162d680d4243b113cb19a53513b9",
            "555aa23347644d60969a4728c5ed71e3",
            "0912b906478d4e1da834d6d659988b77",
            "d568c49eec354a3da65b5068a7f2f938",
            "60e39c038a1d4737b8b80aea3560d35d",
            "4b63ed0b22dc4b18ad1fb75c8c0241b2",
            "6812dcf6697643239f77176d99cfdfcb",
            "08ad0293b15045e1a6dfc48947ed1e22",
            "f556bd0d8457459a8e9ca3ebf16734ab",
            "dc91642f4584439e8d16ac3bf8e296cb",
            "d2d1889f912445eb9cf987ea4701dc63",
            "bfff50ef15df4d588c43123e763dcbcd",
            "de44a06a324445fea14cecc0a3b3a5a8",
            "3a48d8f6d34f458bb553cfe91e14fad2",
            "da3107d259ca4fbc82d0b16bc5a50391",
            "116bf0c85aec4b6387b45e2645094005",
            "870e8abcf1314a0e957c2e8a0544c716",
            "4287012071604f0989f50bc0020cf4b3",
            "b322054572c84ac185348d574711acdb",
            "ca17b9a7c658421fafe7eacf146ac542",
            "07582508632b43b79f4d1e4d8188e605",
            "82e497986e294f2383be37bd531d3313",
            "ed596d09a8ac40dd90574837348c5c14",
            "4b2e9476e2354d629b1bf648687d755e",
            "d3df620db49046928eafe37dcedc6b2b",
            "7cee3f68394f4dfaa8e3e8935e628dd5",
            "e82029be99024e439145999dc7aad2dc",
            "c8fe3cfb959a48ebace22003307c6416",
            "6920e2f7c0fd4b9693fa079d35134f05",
            "da0b586decdf48b5ab170af3f13126ed",
            "c190424dda2349ab8550586fcbd0ae6d",
            "34d81d340e5443f09b66cad39733fe03",
            "3db15f8b64044899afc366d9e2522be6",
            "41ce98f916cb430da77906e3d3392acf",
            "ad46cc46330747f6af273ab9ebb78d9a",
            "a628300859eb4c058b355572426706f5",
            "81b658fb4f69466ebbe9215b85b4666c",
            "0308b0d5630b44f1bba7c1aa5b18d27d",
            "a951723e985a4c3e88820cb182a0a3ce",
            "064d556f5f30494482e7240d5e4deacd",
            "612d211aeaaf405caaa757cc333e2b3c",
            "a9331b2394dd4cbfbc02ba8f1eab0ce9",
            "656e989e37c54ea09713f6ff88a47520",
            "ed0ebc04fe2247639ecc28e8f7638240",
            "31e06cdf02a1462cae86557665c1c690",
            "690420dfa1524c0a846d358f5e0eef76",
            "6fbf41f0a7de42fd85cf2265d99ad609",
            "b976a02a7e9442238df2e28d2c4d210d",
            "5d3d8cc0bf614d79a261b5e5f32af8aa",
            "72f0a8f2fff94671a621fda7250959ee",
            "90e63c7e744047708de213adee53e234",
            "ce679017510c4d9890b9b1c7ce2e341b",
            "c5540f8d756c4bb18c86997e64baaf83",
            "50b9de15b2c24d89a41d93fc7fbed2ba",
            "886ee833e48a4885b38c4777f8937d07",
            "c5323def2c7b4b7683e6cac57a926b0e",
            "6a49a3dd0eb34cfe884653f106052920",
            "8002d77f34864ab6a41bf19188f0e63b",
            "a066fb9fc01044628cfee5d88e75c667",
            "8f322e07a1f4405c86baeac9dc9724cf",
            "648918d608d04f0ba6dac8858530eabe",
            "3b8b2138c30240b5959f4ddec66ecd0f",
            "1f95dacabc414109918d7ca6745fad05",
            "6543de4451cd42aa8186725e7fc936ff",
            "651d92d97521431a94fae57ba4de0587",
            "951ec7c1447f49a1a900056361b3a9c8",
            "6c1e83138b0548d08538fb37639135b4"
          ]
        },
        "id": "e5573d6b",
        "outputId": "0cdb977a-d41d-45b1-8a67-ccd2fcc05d46"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import torch\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# initialize sentiment analysis pipeline with batching to speedup the process\n",
        "sentiment_analyzer = pipeline('sentiment-analysis', batch_size=16, device=0 if torch.cuda.is_available() else -1)\n",
        "\n",
        "# we will use facebook pretrained model, it is quite fast but still returns in good results\n",
        "summarization_tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "summarization_model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "\n",
        "# use GPU if available to speedup more computation\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "summarization_model.to(device)\n",
        "\n",
        "# clean up review data from useless prefix\n",
        "def clean_review(review):\n",
        "    return re.sub(r'^Review:###', '', str(review)).strip()\n",
        "\n",
        "def analyze_review_sentiment(review):\n",
        "    if pd.isna(review) or not review.strip():\n",
        "        return None, None\n",
        "\n",
        "    result = sentiment_analyzer(review[:512])\n",
        "    sentiment = result[0]['label'] if result else None\n",
        "    score = result[0]['score'] if result else None\n",
        "    return sentiment, score\n",
        "\n",
        "def extract_key_aspects(review):\n",
        "    if pd.isna(review) or not review.strip():\n",
        "        return None\n",
        "\n",
        "    review = clean_review(review)\n",
        "\n",
        "    inputs = summarization_tokenizer(\n",
        "        review,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    ).to(device)\n",
        "\n",
        "    # these params should result in good summary results\n",
        "    summary_ids = summarization_model.generate(\n",
        "        **inputs,\n",
        "        max_length=150,\n",
        "        min_length=50,\n",
        "        length_penalty=1.0,\n",
        "        num_beams=6,\n",
        "        repetition_penalty=2.5,\n",
        "        no_repeat_ngram_size=3,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    return summarization_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# sentiment analysis\n",
        "likely_accepted_df['review_sentiment'], likely_accepted_df['review_score'] = zip(*likely_accepted_df['review'].apply(analyze_review_sentiment))\n",
        "\n",
        "# key aspect extraction\n",
        "likely_accepted_df['key_aspects'] = likely_accepted_df['review'].apply(extract_key_aspects)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cKpm7BxntHwm",
      "metadata": {
        "id": "cKpm7BxntHwm"
      },
      "source": [
        "By analyzing the key aspects of the reviews, we can derive a summary of what made a paper good or bad. This involves examining the content and sentiment of each review, which gives us a clear picture of the strengths and weaknesses highlighted by reviewers.\n",
        "\n",
        "We could take this analysis a step further by tokenizing the key aspects to identify specific terms that correlate with paper acceptance or rejection. For instance, if the term \"dense\" is frequently associated with rejections, we could infer that \"dense\" content might negatively affect the chances of acceptance.\n",
        "\n",
        "However, this is a time-consuming process, and implementing it would require a lot of additional resources, time and knowledge, which is beyond the scope of this analysis.\n",
        "\n",
        "In this case, we will focus on the more immediate task of extracting and analyzing key aspects from the reviews, allowing us to draw meaningful conclusions without diving into the more complex task of token-based analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ffb56c94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ffb56c94",
        "outputId": "37fc7db3-ea30-4782-e3de-ed4a61c47737"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "likely_accepted_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-95bbb5e1-a84f-4ce4-b1f8-e744e1ae5612\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>publish_time</th>\n",
              "      <th>abstract</th>\n",
              "      <th>keyword</th>\n",
              "      <th>tL_DL</th>\n",
              "      <th>titlelength</th>\n",
              "      <th>paper_decision_time</th>\n",
              "      <th>paper_decision</th>\n",
              "      <th>paper_decision_comment</th>\n",
              "      <th>paper_decision_commentlength</th>\n",
              "      <th>...</th>\n",
              "      <th>review_score_three</th>\n",
              "      <th>review</th>\n",
              "      <th>review_contentlength</th>\n",
              "      <th>clean_keywords</th>\n",
              "      <th>avg_keyword_acceptance</th>\n",
              "      <th>model_acceptance_score</th>\n",
              "      <th>final_acceptance_score</th>\n",
              "      <th>review_sentiment</th>\n",
              "      <th>review_score</th>\n",
              "      <th>key_aspects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Program Guided Agent | OpenReview</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###Developing agents that can learn t...</td>\n",
              "      <td>Keywords:###Program Execution, Program Executo...</td>\n",
              "      <td>TL;DR:###We propose a modular framework that c...</td>\n",
              "      <td>33</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Accept (Spotlight)</td>\n",
              "      <td>Comment:###This paper provides a fascinating h...</td>\n",
              "      <td>334</td>\n",
              "      <td>...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>Review:###This paper provides a method for ins...</td>\n",
              "      <td>3167</td>\n",
              "      <td>[program execution, program executor, program ...</td>\n",
              "      <td>0.881138</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.880569</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>0.861503</td>\n",
              "      <td>This paper provides a method for instructing a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Program Guided Agent | OpenReview</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###Developing agents that can learn t...</td>\n",
              "      <td>Keywords:###Program Execution, Program Executo...</td>\n",
              "      <td>TL;DR:###We propose a modular framework that c...</td>\n",
              "      <td>33</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Accept (Spotlight)</td>\n",
              "      <td>Comment:###This paper provides a fascinating h...</td>\n",
              "      <td>334</td>\n",
              "      <td>...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>Review:###This paper presents a reinforcement ...</td>\n",
              "      <td>5898</td>\n",
              "      <td>[program execution, program executor, program ...</td>\n",
              "      <td>0.881138</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.880569</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>0.978788</td>\n",
              "      <td>This paper presents a reinforcement learning a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Program Guided Agent | OpenReview</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###Developing agents that can learn t...</td>\n",
              "      <td>Keywords:###Program Execution, Program Executo...</td>\n",
              "      <td>TL;DR:###We propose a modular framework that c...</td>\n",
              "      <td>33</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Accept (Spotlight)</td>\n",
              "      <td>Comment:###This paper provides a fascinating h...</td>\n",
              "      <td>334</td>\n",
              "      <td>...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>Review:###Update: I thank the reviewers for th...</td>\n",
              "      <td>4357</td>\n",
              "      <td>[program execution, program executor, program ...</td>\n",
              "      <td>0.881138</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.880569</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.970360</td>\n",
              "      <td>This paper investigates an important direction...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>InfoGraph: Unsupervised and Semi-supervised Gr...</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###This paper studies learning the re...</td>\n",
              "      <td>Keywords:###graph-level representation learnin...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>128</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Accept (Spotlight)</td>\n",
              "      <td>Comment:###This paper proposes a graph embeddi...</td>\n",
              "      <td>705</td>\n",
              "      <td>...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>Review:###The paper presents a new graph repre...</td>\n",
              "      <td>1852</td>\n",
              "      <td>[graph-level representation learning, mutual i...</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.971016</td>\n",
              "      <td>0.842651</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.996070</td>\n",
              "      <td>The paper presents a new graph representation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>InfoGraph: Unsupervised and Semi-supervised Gr...</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###This paper studies learning the re...</td>\n",
              "      <td>Keywords:###graph-level representation learnin...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>128</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Accept (Spotlight)</td>\n",
              "      <td>Comment:###This paper proposes a graph embeddi...</td>\n",
              "      <td>705</td>\n",
              "      <td>...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>Review:###The paper presents an unsupervised m...</td>\n",
              "      <td>1737</td>\n",
              "      <td>[graph-level representation learning, mutual i...</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.971016</td>\n",
              "      <td>0.842651</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>0.997988</td>\n",
              "      <td>The paper presents an unsupervised method for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>InfoGraph: Unsupervised and Semi-supervised Gr...</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###This paper studies learning the re...</td>\n",
              "      <td>Keywords:###graph-level representation learnin...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>128</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Accept (Spotlight)</td>\n",
              "      <td>Comment:###This paper proposes a graph embeddi...</td>\n",
              "      <td>705</td>\n",
              "      <td>...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>Review:###In this paper, the authors propose a...</td>\n",
              "      <td>2143</td>\n",
              "      <td>[graph-level representation learning, mutual i...</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.971016</td>\n",
              "      <td>0.842651</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.986369</td>\n",
              "      <td>In this paper, the authors propose a graph-lev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>On Robustness of Neural Ordinary Differential ...</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###Neural ordinary differential equat...</td>\n",
              "      <td>Keywords:###Neural ODE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>68</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Accept (Spotlight)</td>\n",
              "      <td>Comment:###This paper studies the robustness o...</td>\n",
              "      <td>316</td>\n",
              "      <td>...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>Review:###This paper investigates the robustne...</td>\n",
              "      <td>1289</td>\n",
              "      <td>[neural ode]</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.971079</td>\n",
              "      <td>0.985540</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.998732</td>\n",
              "      <td>This paper investigates the robustness of Neur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>On Robustness of Neural Ordinary Differential ...</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###Neural ordinary differential equat...</td>\n",
              "      <td>Keywords:###Neural ODE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>68</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Accept (Spotlight)</td>\n",
              "      <td>Comment:###This paper studies the robustness o...</td>\n",
              "      <td>316</td>\n",
              "      <td>...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>Review:###The paper is concerned with neural O...</td>\n",
              "      <td>2119</td>\n",
              "      <td>[neural ode]</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.971079</td>\n",
              "      <td>0.985540</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.999268</td>\n",
              "      <td>The paper is concerned with neural ODE-based n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>On Robustness of Neural Ordinary Differential ...</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###Neural ordinary differential equat...</td>\n",
              "      <td>Keywords:###Neural ODE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>68</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Accept (Spotlight)</td>\n",
              "      <td>Comment:###This paper studies the robustness o...</td>\n",
              "      <td>316</td>\n",
              "      <td>...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>This paper studied the robustness of neural O...</td>\n",
              "      <td>2981</td>\n",
              "      <td>[neural ode]</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.971079</td>\n",
              "      <td>0.985540</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.994699</td>\n",
              "      <td>This paper studied the robustness of neural OD...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Estimating Gradients for Discrete Random Varia...</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###We derive an unbiased estimator fo...</td>\n",
              "      <td>Keywords:###gradient, estimator, discrete, cat...</td>\n",
              "      <td>TL;DR:###We derive a low-variance, unbiased gr...</td>\n",
              "      <td>95</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Accept (Spotlight)</td>\n",
              "      <td>Comment:###The authors derive a novel, unbiase...</td>\n",
              "      <td>1119</td>\n",
              "      <td>...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>Summary: This paper introduces an gradient es...</td>\n",
              "      <td>1934</td>\n",
              "      <td>[gradient, estimator, discrete, categorical, s...</td>\n",
              "      <td>0.879545</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.929773</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>0.997027</td>\n",
              "      <td>An estimator over a discrete distribution can ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Estimating Gradients for Discrete Random Varia...</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###We derive an unbiased estimator fo...</td>\n",
              "      <td>Keywords:###gradient, estimator, discrete, cat...</td>\n",
              "      <td>TL;DR:###We derive a low-variance, unbiased gr...</td>\n",
              "      <td>95</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Accept (Spotlight)</td>\n",
              "      <td>Comment:###The authors derive a novel, unbiase...</td>\n",
              "      <td>1119</td>\n",
              "      <td>...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>Review:###Summary: In this paper, an unbiased ...</td>\n",
              "      <td>3474</td>\n",
              "      <td>[gradient, estimator, discrete, categorical, s...</td>\n",
              "      <td>0.879545</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.929773</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>0.893269</td>\n",
              "      <td>In this paper, an unbiased estimator for expec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Estimating Gradients for Discrete Random Varia...</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###We derive an unbiased estimator fo...</td>\n",
              "      <td>Keywords:###gradient, estimator, discrete, cat...</td>\n",
              "      <td>TL;DR:###We derive a low-variance, unbiased gr...</td>\n",
              "      <td>95</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Accept (Spotlight)</td>\n",
              "      <td>Comment:###The authors derive a novel, unbiase...</td>\n",
              "      <td>1119</td>\n",
              "      <td>...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>Review:###Edited after rebuttal: I*m satisfied...</td>\n",
              "      <td>4657</td>\n",
              "      <td>[gradient, estimator, discrete, categorical, s...</td>\n",
              "      <td>0.879545</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.929773</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.992608</td>\n",
              "      <td>The authors develop a generic method for estim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>A Signal Propagation Perspective for Pruning N...</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###Network pruning is a promising ave...</td>\n",
              "      <td>Keywords:###neural network pruning, signal pro...</td>\n",
              "      <td>TL;DR:###We formally characterize the initiali...</td>\n",
              "      <td>91</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Accept (Spotlight)</td>\n",
              "      <td>Comment:###This is a strong submission, and I ...</td>\n",
              "      <td>1019</td>\n",
              "      <td>...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>Review:###In this paper, the authors studied a...</td>\n",
              "      <td>1401</td>\n",
              "      <td>[neural network pruning, signal propagation pe...</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.950916</td>\n",
              "      <td>0.892125</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.905243</td>\n",
              "      <td>In this paper, the authors studied and formali...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>A Signal Propagation Perspective for Pruning N...</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###Network pruning is a promising ave...</td>\n",
              "      <td>Keywords:###neural network pruning, signal pro...</td>\n",
              "      <td>TL;DR:###We formally characterize the initiali...</td>\n",
              "      <td>91</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Accept (Spotlight)</td>\n",
              "      <td>Comment:###This is a strong submission, and I ...</td>\n",
              "      <td>1019</td>\n",
              "      <td>...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>This paper analyzes how signals propagate thr...</td>\n",
              "      <td>2377</td>\n",
              "      <td>[neural network pruning, signal propagation pe...</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.950916</td>\n",
              "      <td>0.892125</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.927971</td>\n",
              "      <td>This paper analyzes how signals propagate thro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>A Signal Propagation Perspective for Pruning N...</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###Network pruning is a promising ave...</td>\n",
              "      <td>Keywords:###neural network pruning, signal pro...</td>\n",
              "      <td>TL;DR:###We formally characterize the initiali...</td>\n",
              "      <td>91</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Accept (Spotlight)</td>\n",
              "      <td>Comment:###This is a strong submission, and I ...</td>\n",
              "      <td>1019</td>\n",
              "      <td>...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>Review:###The paper introduces a signal propag...</td>\n",
              "      <td>1742</td>\n",
              "      <td>[neural network pruning, signal propagation pe...</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.950916</td>\n",
              "      <td>0.892125</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.709700</td>\n",
              "      <td>The paper introduces a signal propagation pers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>WHITE NOISE ANALYSIS OF NEURAL NETWORKS | Open...</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###A white noise analysis of modern d...</td>\n",
              "      <td>Keywords:###Classification images, spike trigg...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>52</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Accept (Spotlight)</td>\n",
              "      <td>Comment:###All the reviewers found the paper t...</td>\n",
              "      <td>186</td>\n",
              "      <td>...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>This work inspects the bias existing in the n...</td>\n",
              "      <td>2626</td>\n",
              "      <td>[classification images, spike triggered analys...</td>\n",
              "      <td>0.747888</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>0.843944</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>0.792912</td>\n",
              "      <td>This work inspects the bias existing in the ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>WHITE NOISE ANALYSIS OF NEURAL NETWORKS | Open...</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###A white noise analysis of modern d...</td>\n",
              "      <td>Keywords:###Classification images, spike trigg...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>52</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Accept (Spotlight)</td>\n",
              "      <td>Comment:###All the reviewers found the paper t...</td>\n",
              "      <td>186</td>\n",
              "      <td>...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>Review:###Summary: This paper introduces two t...</td>\n",
              "      <td>1160</td>\n",
              "      <td>[classification images, spike triggered analys...</td>\n",
              "      <td>0.747888</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>0.843944</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.961289</td>\n",
              "      <td>The broad goal of the paper is to add more too...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>WHITE NOISE ANALYSIS OF NEURAL NETWORKS | Open...</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###A white noise analysis of modern d...</td>\n",
              "      <td>Keywords:###Classification images, spike trigg...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>52</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Accept (Spotlight)</td>\n",
              "      <td>Comment:###All the reviewers found the paper t...</td>\n",
              "      <td>186</td>\n",
              "      <td>...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>Review:###This is an interesting paper that us...</td>\n",
              "      <td>1860</td>\n",
              "      <td>[classification images, spike triggered analys...</td>\n",
              "      <td>0.747888</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>0.843944</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.999163</td>\n",
              "      <td>This is an interesting paper that uses two tec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>WHITE NOISE ANALYSIS OF NEURAL NETWORKS | Open...</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###A white noise analysis of modern d...</td>\n",
              "      <td>Keywords:###Classification images, spike trigg...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>52</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Accept (Spotlight)</td>\n",
              "      <td>Comment:###All the reviewers found the paper t...</td>\n",
              "      <td>186</td>\n",
              "      <td>...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>This paper uses classification images and spi...</td>\n",
              "      <td>943</td>\n",
              "      <td>[classification images, spike triggered analys...</td>\n",
              "      <td>0.747888</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>0.843944</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.998932</td>\n",
              "      <td>This paper uses classification images and spik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Online and stochastic optimization beyond Lips...</td>\n",
              "      <td>26 Sep 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Abstract:###Motivated by applications to machi...</td>\n",
              "      <td>Keywords:###Online optimization, stochastic op...</td>\n",
              "      <td>TL;DR:###We introduce a novel version of Lipsc...</td>\n",
              "      <td>98</td>\n",
              "      <td>20 Dec 2019 (modified: 20 Dec 2019)</td>\n",
              "      <td>Decision:###Accept (Spotlight)</td>\n",
              "      <td>Comment:###This is a mostly theoretical paper ...</td>\n",
              "      <td>781</td>\n",
              "      <td>...</td>\n",
              "      <td>Review Assessment: Checking Correctness Of Der...</td>\n",
              "      <td>Review:###The paper establishes optimal regret...</td>\n",
              "      <td>2706</td>\n",
              "      <td>[online optimization, stochastic optimization,...</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.921725</td>\n",
              "      <td>0.856696</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>0.997472</td>\n",
              "      <td>The paper establishes optimal bounds of the or...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20 rows  26 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95bbb5e1-a84f-4ce4-b1f8-e744e1ae5612')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-95bbb5e1-a84f-4ce4-b1f8-e744e1ae5612 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-95bbb5e1-a84f-4ce4-b1f8-e744e1ae5612');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c83e6400-0d0f-474d-ba19-dd19fd995897\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c83e6400-0d0f-474d-ba19-dd19fd995897')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c83e6400-0d0f-474d-ba19-dd19fd995897 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                title  \\\n",
              "0                   Program Guided Agent | OpenReview   \n",
              "1                   Program Guided Agent | OpenReview   \n",
              "2                   Program Guided Agent | OpenReview   \n",
              "3   InfoGraph: Unsupervised and Semi-supervised Gr...   \n",
              "4   InfoGraph: Unsupervised and Semi-supervised Gr...   \n",
              "5   InfoGraph: Unsupervised and Semi-supervised Gr...   \n",
              "6   On Robustness of Neural Ordinary Differential ...   \n",
              "7   On Robustness of Neural Ordinary Differential ...   \n",
              "8   On Robustness of Neural Ordinary Differential ...   \n",
              "9   Estimating Gradients for Discrete Random Varia...   \n",
              "10  Estimating Gradients for Discrete Random Varia...   \n",
              "11  Estimating Gradients for Discrete Random Varia...   \n",
              "12  A Signal Propagation Perspective for Pruning N...   \n",
              "13  A Signal Propagation Perspective for Pruning N...   \n",
              "14  A Signal Propagation Perspective for Pruning N...   \n",
              "15  WHITE NOISE ANALYSIS OF NEURAL NETWORKS | Open...   \n",
              "16  WHITE NOISE ANALYSIS OF NEURAL NETWORKS | Open...   \n",
              "17  WHITE NOISE ANALYSIS OF NEURAL NETWORKS | Open...   \n",
              "18  WHITE NOISE ANALYSIS OF NEURAL NETWORKS | Open...   \n",
              "19  Online and stochastic optimization beyond Lips...   \n",
              "\n",
              "                           publish_time  \\\n",
              "0   26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "1   26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "2   26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "3   26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "4   26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "5   26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "6   26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "7   26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "8   26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "9   26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "10  26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "11  26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "12  26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "13  26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "14  26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "15  26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "16  26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "17  26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "18  26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "19  26 Sep 2019 (modified: 20 Dec 2019)   \n",
              "\n",
              "                                             abstract  \\\n",
              "0   Abstract:###Developing agents that can learn t...   \n",
              "1   Abstract:###Developing agents that can learn t...   \n",
              "2   Abstract:###Developing agents that can learn t...   \n",
              "3   Abstract:###This paper studies learning the re...   \n",
              "4   Abstract:###This paper studies learning the re...   \n",
              "5   Abstract:###This paper studies learning the re...   \n",
              "6   Abstract:###Neural ordinary differential equat...   \n",
              "7   Abstract:###Neural ordinary differential equat...   \n",
              "8   Abstract:###Neural ordinary differential equat...   \n",
              "9   Abstract:###We derive an unbiased estimator fo...   \n",
              "10  Abstract:###We derive an unbiased estimator fo...   \n",
              "11  Abstract:###We derive an unbiased estimator fo...   \n",
              "12  Abstract:###Network pruning is a promising ave...   \n",
              "13  Abstract:###Network pruning is a promising ave...   \n",
              "14  Abstract:###Network pruning is a promising ave...   \n",
              "15  Abstract:###A white noise analysis of modern d...   \n",
              "16  Abstract:###A white noise analysis of modern d...   \n",
              "17  Abstract:###A white noise analysis of modern d...   \n",
              "18  Abstract:###A white noise analysis of modern d...   \n",
              "19  Abstract:###Motivated by applications to machi...   \n",
              "\n",
              "                                              keyword  \\\n",
              "0   Keywords:###Program Execution, Program Executo...   \n",
              "1   Keywords:###Program Execution, Program Executo...   \n",
              "2   Keywords:###Program Execution, Program Executo...   \n",
              "3   Keywords:###graph-level representation learnin...   \n",
              "4   Keywords:###graph-level representation learnin...   \n",
              "5   Keywords:###graph-level representation learnin...   \n",
              "6                              Keywords:###Neural ODE   \n",
              "7                              Keywords:###Neural ODE   \n",
              "8                              Keywords:###Neural ODE   \n",
              "9   Keywords:###gradient, estimator, discrete, cat...   \n",
              "10  Keywords:###gradient, estimator, discrete, cat...   \n",
              "11  Keywords:###gradient, estimator, discrete, cat...   \n",
              "12  Keywords:###neural network pruning, signal pro...   \n",
              "13  Keywords:###neural network pruning, signal pro...   \n",
              "14  Keywords:###neural network pruning, signal pro...   \n",
              "15  Keywords:###Classification images, spike trigg...   \n",
              "16  Keywords:###Classification images, spike trigg...   \n",
              "17  Keywords:###Classification images, spike trigg...   \n",
              "18  Keywords:###Classification images, spike trigg...   \n",
              "19  Keywords:###Online optimization, stochastic op...   \n",
              "\n",
              "                                                tL_DL  titlelength  \\\n",
              "0   TL;DR:###We propose a modular framework that c...           33   \n",
              "1   TL;DR:###We propose a modular framework that c...           33   \n",
              "2   TL;DR:###We propose a modular framework that c...           33   \n",
              "3                                                 NaN          128   \n",
              "4                                                 NaN          128   \n",
              "5                                                 NaN          128   \n",
              "6                                                 NaN           68   \n",
              "7                                                 NaN           68   \n",
              "8                                                 NaN           68   \n",
              "9   TL;DR:###We derive a low-variance, unbiased gr...           95   \n",
              "10  TL;DR:###We derive a low-variance, unbiased gr...           95   \n",
              "11  TL;DR:###We derive a low-variance, unbiased gr...           95   \n",
              "12  TL;DR:###We formally characterize the initiali...           91   \n",
              "13  TL;DR:###We formally characterize the initiali...           91   \n",
              "14  TL;DR:###We formally characterize the initiali...           91   \n",
              "15                                                NaN           52   \n",
              "16                                                NaN           52   \n",
              "17                                                NaN           52   \n",
              "18                                                NaN           52   \n",
              "19  TL;DR:###We introduce a novel version of Lipsc...           98   \n",
              "\n",
              "                    paper_decision_time                  paper_decision  \\\n",
              "0   20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Accept (Spotlight)   \n",
              "1   20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Accept (Spotlight)   \n",
              "2   20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Accept (Spotlight)   \n",
              "3   20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Accept (Spotlight)   \n",
              "4   20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Accept (Spotlight)   \n",
              "5   20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Accept (Spotlight)   \n",
              "6   20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Accept (Spotlight)   \n",
              "7   20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Accept (Spotlight)   \n",
              "8   20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Accept (Spotlight)   \n",
              "9   20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Accept (Spotlight)   \n",
              "10  20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Accept (Spotlight)   \n",
              "11  20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Accept (Spotlight)   \n",
              "12  20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Accept (Spotlight)   \n",
              "13  20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Accept (Spotlight)   \n",
              "14  20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Accept (Spotlight)   \n",
              "15  20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Accept (Spotlight)   \n",
              "16  20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Accept (Spotlight)   \n",
              "17  20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Accept (Spotlight)   \n",
              "18  20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Accept (Spotlight)   \n",
              "19  20 Dec 2019 (modified: 20 Dec 2019)  Decision:###Accept (Spotlight)   \n",
              "\n",
              "                               paper_decision_comment  \\\n",
              "0   Comment:###This paper provides a fascinating h...   \n",
              "1   Comment:###This paper provides a fascinating h...   \n",
              "2   Comment:###This paper provides a fascinating h...   \n",
              "3   Comment:###This paper proposes a graph embeddi...   \n",
              "4   Comment:###This paper proposes a graph embeddi...   \n",
              "5   Comment:###This paper proposes a graph embeddi...   \n",
              "6   Comment:###This paper studies the robustness o...   \n",
              "7   Comment:###This paper studies the robustness o...   \n",
              "8   Comment:###This paper studies the robustness o...   \n",
              "9   Comment:###The authors derive a novel, unbiase...   \n",
              "10  Comment:###The authors derive a novel, unbiase...   \n",
              "11  Comment:###The authors derive a novel, unbiase...   \n",
              "12  Comment:###This is a strong submission, and I ...   \n",
              "13  Comment:###This is a strong submission, and I ...   \n",
              "14  Comment:###This is a strong submission, and I ...   \n",
              "15  Comment:###All the reviewers found the paper t...   \n",
              "16  Comment:###All the reviewers found the paper t...   \n",
              "17  Comment:###All the reviewers found the paper t...   \n",
              "18  Comment:###All the reviewers found the paper t...   \n",
              "19  Comment:###This is a mostly theoretical paper ...   \n",
              "\n",
              "    paper_decision_commentlength  ...  \\\n",
              "0                            334  ...   \n",
              "1                            334  ...   \n",
              "2                            334  ...   \n",
              "3                            705  ...   \n",
              "4                            705  ...   \n",
              "5                            705  ...   \n",
              "6                            316  ...   \n",
              "7                            316  ...   \n",
              "8                            316  ...   \n",
              "9                           1119  ...   \n",
              "10                          1119  ...   \n",
              "11                          1119  ...   \n",
              "12                          1019  ...   \n",
              "13                          1019  ...   \n",
              "14                          1019  ...   \n",
              "15                           186  ...   \n",
              "16                           186  ...   \n",
              "17                           186  ...   \n",
              "18                           186  ...   \n",
              "19                           781  ...   \n",
              "\n",
              "                                   review_score_three  \\\n",
              "0   Review Assessment: Checking Correctness Of Der...   \n",
              "1   Review Assessment: Checking Correctness Of Der...   \n",
              "2   Review Assessment: Checking Correctness Of Der...   \n",
              "3   Review Assessment: Checking Correctness Of Der...   \n",
              "4   Review Assessment: Checking Correctness Of Der...   \n",
              "5   Review Assessment: Checking Correctness Of Der...   \n",
              "6   Review Assessment: Checking Correctness Of Der...   \n",
              "7   Review Assessment: Checking Correctness Of Der...   \n",
              "8   Review Assessment: Checking Correctness Of Der...   \n",
              "9   Review Assessment: Checking Correctness Of Der...   \n",
              "10  Review Assessment: Checking Correctness Of Der...   \n",
              "11  Review Assessment: Checking Correctness Of Der...   \n",
              "12  Review Assessment: Checking Correctness Of Der...   \n",
              "13  Review Assessment: Checking Correctness Of Der...   \n",
              "14  Review Assessment: Checking Correctness Of Der...   \n",
              "15  Review Assessment: Checking Correctness Of Der...   \n",
              "16  Review Assessment: Checking Correctness Of Der...   \n",
              "17  Review Assessment: Checking Correctness Of Der...   \n",
              "18  Review Assessment: Checking Correctness Of Der...   \n",
              "19  Review Assessment: Checking Correctness Of Der...   \n",
              "\n",
              "                                               review review_contentlength  \\\n",
              "0   Review:###This paper provides a method for ins...                 3167   \n",
              "1   Review:###This paper presents a reinforcement ...                 5898   \n",
              "2   Review:###Update: I thank the reviewers for th...                 4357   \n",
              "3   Review:###The paper presents a new graph repre...                 1852   \n",
              "4   Review:###The paper presents an unsupervised m...                 1737   \n",
              "5   Review:###In this paper, the authors propose a...                 2143   \n",
              "6   Review:###This paper investigates the robustne...                 1289   \n",
              "7   Review:###The paper is concerned with neural O...                 2119   \n",
              "8    This paper studied the robustness of neural O...                 2981   \n",
              "9    Summary: This paper introduces an gradient es...                 1934   \n",
              "10  Review:###Summary: In this paper, an unbiased ...                 3474   \n",
              "11  Review:###Edited after rebuttal: I*m satisfied...                 4657   \n",
              "12  Review:###In this paper, the authors studied a...                 1401   \n",
              "13   This paper analyzes how signals propagate thr...                 2377   \n",
              "14  Review:###The paper introduces a signal propag...                 1742   \n",
              "15   This work inspects the bias existing in the n...                 2626   \n",
              "16  Review:###Summary: This paper introduces two t...                 1160   \n",
              "17  Review:###This is an interesting paper that us...                 1860   \n",
              "18   This paper uses classification images and spi...                  943   \n",
              "19  Review:###The paper establishes optimal regret...                 2706   \n",
              "\n",
              "                                       clean_keywords avg_keyword_acceptance  \\\n",
              "0   [program execution, program executor, program ...               0.881138   \n",
              "1   [program execution, program executor, program ...               0.881138   \n",
              "2   [program execution, program executor, program ...               0.881138   \n",
              "3   [graph-level representation learning, mutual i...               0.714286   \n",
              "4   [graph-level representation learning, mutual i...               0.714286   \n",
              "5   [graph-level representation learning, mutual i...               0.714286   \n",
              "6                                        [neural ode]               1.000000   \n",
              "7                                        [neural ode]               1.000000   \n",
              "8                                        [neural ode]               1.000000   \n",
              "9   [gradient, estimator, discrete, categorical, s...               0.879545   \n",
              "10  [gradient, estimator, discrete, categorical, s...               0.879545   \n",
              "11  [gradient, estimator, discrete, categorical, s...               0.879545   \n",
              "12  [neural network pruning, signal propagation pe...               0.833333   \n",
              "13  [neural network pruning, signal propagation pe...               0.833333   \n",
              "14  [neural network pruning, signal propagation pe...               0.833333   \n",
              "15  [classification images, spike triggered analys...               0.747888   \n",
              "16  [classification images, spike triggered analys...               0.747888   \n",
              "17  [classification images, spike triggered analys...               0.747888   \n",
              "18  [classification images, spike triggered analys...               0.747888   \n",
              "19  [online optimization, stochastic optimization,...               0.791667   \n",
              "\n",
              "   model_acceptance_score final_acceptance_score review_sentiment  \\\n",
              "0                0.880000               0.880569         NEGATIVE   \n",
              "1                0.880000               0.880569         NEGATIVE   \n",
              "2                0.880000               0.880569         POSITIVE   \n",
              "3                0.971016               0.842651         POSITIVE   \n",
              "4                0.971016               0.842651         NEGATIVE   \n",
              "5                0.971016               0.842651         POSITIVE   \n",
              "6                0.971079               0.985540         POSITIVE   \n",
              "7                0.971079               0.985540         POSITIVE   \n",
              "8                0.971079               0.985540         POSITIVE   \n",
              "9                0.980000               0.929773         NEGATIVE   \n",
              "10               0.980000               0.929773         NEGATIVE   \n",
              "11               0.980000               0.929773         POSITIVE   \n",
              "12               0.950916               0.892125         POSITIVE   \n",
              "13               0.950916               0.892125         POSITIVE   \n",
              "14               0.950916               0.892125         POSITIVE   \n",
              "15               0.940000               0.843944         NEGATIVE   \n",
              "16               0.940000               0.843944         POSITIVE   \n",
              "17               0.940000               0.843944         POSITIVE   \n",
              "18               0.940000               0.843944         POSITIVE   \n",
              "19               0.921725               0.856696         NEGATIVE   \n",
              "\n",
              "    review_score                                        key_aspects  \n",
              "0       0.861503  This paper provides a method for instructing a...  \n",
              "1       0.978788  This paper presents a reinforcement learning a...  \n",
              "2       0.970360  This paper investigates an important direction...  \n",
              "3       0.996070  The paper presents a new graph representation ...  \n",
              "4       0.997988  The paper presents an unsupervised method for ...  \n",
              "5       0.986369  In this paper, the authors propose a graph-lev...  \n",
              "6       0.998732  This paper investigates the robustness of Neur...  \n",
              "7       0.999268  The paper is concerned with neural ODE-based n...  \n",
              "8       0.994699  This paper studied the robustness of neural OD...  \n",
              "9       0.997027  An estimator over a discrete distribution can ...  \n",
              "10      0.893269  In this paper, an unbiased estimator for expec...  \n",
              "11      0.992608  The authors develop a generic method for estim...  \n",
              "12      0.905243  In this paper, the authors studied and formali...  \n",
              "13      0.927971  This paper analyzes how signals propagate thro...  \n",
              "14      0.709700  The paper introduces a signal propagation pers...  \n",
              "15      0.792912  This work inspects the bias existing in the ne...  \n",
              "16      0.961289  The broad goal of the paper is to add more too...  \n",
              "17      0.999163  This is an interesting paper that uses two tec...  \n",
              "18      0.998932  This paper uses classification images and spik...  \n",
              "19      0.997472  The paper establishes optimal bounds of the or...  \n",
              "\n",
              "[20 rows x 26 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "likely_accepted_df.to_excel(\"likely_accepted_papers_key_aspects.xlsx\")\n",
        "likely_accepted_df.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xNiLqk9S9GIR",
      "metadata": {
        "id": "xNiLqk9S9GIR"
      },
      "source": [
        "As seen in the output, the model not only generates a sentiment for each paper, with a corresponding confidence score (indicating the model's certainty), but also provides a brief summary explaining the reasons behind the sentiment. This summary helps us understand why a paper is considered positive or negative.\n",
        "\n",
        "Additionally, it's worth noting that the first three lines in the output pertain to the same paper but show three different outcomes. This is particularly insightful for two reasons:\n",
        "\n",
        "- We can observe that the same paper underwent several reviews, each with different feedback.\n",
        "\n",
        "- By analyzing these changing outcomes, we can gain insights into how the paper evolved and what improvements were made in response to reviewer feedback. This also sheds light on what the reviewers liked and, more importantly, what to avoid in future submissions to minimize the risk of rejection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "GWZvMqkd9985",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWZvMqkd9985",
        "outputId": "c638145d-f008-404e-e7bc-e2e40240b0a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== PAPER: Program Guided Agent | OpenReview ===\n",
            "\n",
            "=== Key Aspects from review 1 ===\n",
            "This paper provides a method for instructing an agent using programs as input instructions. The\n",
            "arguments in this paper are well made but the paper would benefit from better clarifying several\n",
            "points. In particular, it was unclear how the DSL comes about and what restrictions it places on the\n",
            "problem.\n",
            "\n",
            "=== Key Aspects from review 2 ===\n",
            "This paper presents a reinforcement learning agent that learns to execute tasks specified in a form\n",
            "of programs with an architecture consisting of three modules. The (fixed) interpreter module\n",
            "interprets the program, by issuing queries to a (pre-trained) vision module and giving goals to a\n",
            "policy module that executes them in the environment. The paper also introduces a policy modulation\n",
            "technique, with the goal of modulating the current state with the expected (symbolic) goal. The\n",
            "model is evaluated on a 2D approximation of Minecraft, where it outperforms a set of baselines.\n",
            "\n",
            "=== Key Aspects from review 3 ===\n",
            "This paper investigates an important direction: How can RL agents make use of high-level\n",
            "instructions and task decompositions formalized as programs? The authors propose a model for a\n",
            "program guided agent that, conditioned on a program, interprets the program, executes it to query a\n",
            "perception module and subsequently proposes subgoals. The method outperforms LSTM and Transformer\n",
            "baselines on a Minecraft-like task and generalizes to programs larger than the one seen during\n",
            "training.\n",
            "\n",
            "=== PAPER: WHITE NOISE ANALYSIS OF NEURAL NETWORKS | OpenReview ===\n",
            "\n",
            "=== Key Aspects from review 1 ===\n",
            "This work inspects the bias existing in the neural network classifiers through two techniques from\n",
            "computational neuroscience, the classification image techniques and spike-triggered covariance (STA)\n",
            "analysis. The authors use the two tools to visualize the bias learned by various classifiers, CNN,\n",
            "MLP, and logistic regression, trained on three datasets MNIST, Fashion-MNIST and CIFAR 10.\n",
            "\n",
            "=== Key Aspects from review 2 ===\n",
            "The broad goal of the paper is to add more tooling to add interpretability and robustness to a\n",
            "neural network. Spike-triggered analysis can be understood as measuring a neuron*s response to time-\n",
            "varying stimuli. The paper has the potential to inspire future research in this direction.\n",
            "\n",
            "=== Key Aspects from review 3 ===\n",
            "This is an interesting paper that uses two techniques from neuroscience (eletrophysiology) to\n",
            "interpret CNNs. The authors find interesting similarities between CNNs and animal/human brain such\n",
            "as the shift of the psychometric curve. This paper has comprehensive use of neuroscience method,\n",
            "nicely bringing the two fields together.\n",
            "\n",
            "=== Key Aspects from review 4 ===\n",
            "This paper uses classification images and spike triggered averages to reveal hidden structure in\n",
            "deep neural networks. The authors also show how the method can be used for black-box adversarial\n",
            "attacks without need for gradients or logits. I don't feel there is quite enough insights here for\n",
            "ICLR publication.\n"
          ]
        }
      ],
      "source": [
        "likely_accepted_df = likely_accepted_df.reset_index()\n",
        "\n",
        "import textwrap\n",
        "\n",
        "def print_key_aspects_by_title(paper_title):\n",
        "    subset = likely_accepted_df[likely_accepted_df[\"title\"] == paper_title]\n",
        "\n",
        "    if subset.empty:\n",
        "        print(f\"No reviews found for title: {paper_title}\")\n",
        "        return\n",
        "\n",
        "    cleaned = subset[\"key_aspects\"].str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
        "\n",
        "    for i, text in enumerate(cleaned, start=1):\n",
        "        print(f\"\\n=== Key Aspects from review {i} ===\")\n",
        "        print(\"\\n\".join(textwrap.wrap(text, width=100)))\n",
        "\n",
        "print(\"\\n=== PAPER: Program Guided Agent | OpenReview ===\")\n",
        "print_key_aspects_by_title(\"Program Guided Agent | OpenReview\")\n",
        "\n",
        "print(\"\\n=== PAPER: WHITE NOISE ANALYSIS OF NEURAL NETWORKS | OpenReview ===\")\n",
        "print_key_aspects_by_title(\"WHITE NOISE ANALYSIS OF NEURAL NETWORKS | OpenReview\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5151bd8c",
      "metadata": {},
      "source": [
        "As it is possible to see, we obtain the key aspects of each review made to the requested paper. Another observation that can be made is that the review sentiment is not necessarily a positive one but, as it is normal through different review iterations, a negative one.\n",
        "\n",
        "For example, for the first paper \"Program Guided Agent | Openreivew\" we obtained that it received three reviews, all of which provide useful insight into how it was perceived throughout the review process.\n",
        "\n",
        "The **first review** presents a mixed perspective. While it acknowledges that the paper makes solid arguments, it also points out that some important details were unclearspecifically, the origin and limitations of the domain-specific language (DSL) used to guide the agent. This indicates that, at this stage, the reviewer saw potential in the paper but felt it needed clearer exposition.\n",
        "\n",
        "The **second review** is more positive. It appreciates the architecture proposed by the authors, particularly the modular structure involving a fixed interpreter, a vision module, and a policy module. The reviewer also highlights the novelty of the proposed policy modulation technique and notes strong experimental results in a Minecraft-like environment, where the method outperforms baseline models. This review signals a favorable impression of both the paper's technical contribution and its empirical validation.\n",
        "\n",
        "The **third review** is very supportive and emphasizes the importance of the research direction. It praises the approach of using programs to guide reinforcement learning agents and commends the papers ability to generalize to larger, unseen program inputs. The tone here clearly leans toward acceptance, reinforcing the idea that the paper addresses a valuable problem and offers a strong, well-tested solution.\n",
        "\n",
        "This progression highlights how iterative feedback and refinement can turn a promising but initially unclear submission into a well-received paper. It further illustrates how identifying and addressing reviewer concerns early on can significantly impact a papers final outcome.\n",
        "\n",
        "\n",
        "How can we apply these information for a paper that we are writing or also as a general tip on writing good papers?\n",
        "\n",
        "### For a similar specific topic\n",
        "First, clarity is fundamental. One reviewer pointed out that certain components, like the DSL (domain-specific language), were not clearly explained. If your paper uses a custom language, module, or framework, its important to define it thoroughly, explain how it is constructed, and describe any limitations it may have.\n",
        "\n",
        "Second, the reviewers responded positively to a modular approach in the model architecture. If your paper uses a system composed of multiple interacting parts, be sure to describe each modules role clearly, how they interact, and what the benefit of this design is.\n",
        "\n",
        "Third, even small contributions like introducing a new mechanism (in this case, policy modulation) were appreciated. If your work includes similar technical contributions, highlight them clearly, give them a name, and show how they impact performance through experiments or ablation studies.\n",
        "\n",
        "Another key point is generalization. Reviewers noted that the model generalized to more complex tasks than those seen during training. If your method can generalize to different settings or more complex cases, make sure to demonstrate and emphasize this. Generalization is often considered a strong indicator of a models robustness and applicability.\n",
        "\n",
        "### Beyond specific topic\n",
        "Beyond specific content, the reviews show that reviewers value both technical performance and the broader research direction. Even if your results are modest, positioning your work as contributing to a long-term research question can make it more compelling.\n",
        "\n",
        "Lastly, your paper structure matters. Reviewers often form their impressions based on the abstract, introduction, and visual elements. Make sure these parts are clear, concise, and informative, as they are likely to be the first things readers will engage with.\n",
        "\n",
        "\n",
        "If we put together all the key aspects of each papers' review, we can derive a database of information on how to both write papers for a specific topic but also determine \"general rules\" on how to write nice papers."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "q2pJYmS7U7ql",
      "metadata": {
        "id": "q2pJYmS7U7ql"
      },
      "source": [
        "# Conclusion\n",
        "To understand what contributes to a paper being accepted  and therefore how to write better papers  I based my methodology on analyzing features of already accepted papers. The intuition is simple: if we want to write better papers, we should learn from the ones that succeeded.\n",
        "\n",
        "Specifically, I combined two complementary sources of information:\n",
        "\n",
        "- Keyword-based acceptance rate, this provides a simple and fast value by analyzing how often certain keywords appear in accepted papers. It reflects the historical success of topics and terminology in the field. By identifying high-acceptance-rate keywords, we can understand the topics that are more likely to align with the expectations of the reviewing community.\n",
        "\n",
        "- Machine learning model prediction, a Random Forest classifier was trained on labeled data (accepted vs. rejected) using keyword features. This adds a data-driven perspective, capturing patterns and interactions not immediately obvious through traditional statistics alone. The model allows us to quantify the importance of each keyword, providing insights into which topics or terms have a stronger correlation with acceptance or rejection.\n",
        "\n",
        "By averaging these two components, I created a more balanced and explainable score, the final acceptance likelihood. This score allows us to:\n",
        "\n",
        "- Identify keywords and topics that are statistically linked with acceptance, highlighting trends in successful research.\n",
        "\n",
        "- Estimate a paper's chances of being accepted based on its content, providing authors with a metric that quantifies their paper's alignment with successful patterns.\n",
        "\n",
        "- Provide actionable feedback to authors, guiding them on how to align their paper with historically accepted research.\n",
        "\n",
        "However, understanding what not to do is equally important. Therefore, this same approach can be extended to rejected papers, helping highlight topics, structures, or keyword combinations that are statistically less successful. These insights provide negative signals, things to avoid or improve, which are just as valuable as positive patterns.\n",
        "\n",
        "Furthermore, by analyzing the key aspects of accepted papers (as extracted from their reviews), we can distill common themes and feedback that led to their success. By training a machine learning model on this data, we could even create a generalizable guide on how to write successful papers based on the specific elements that reviewers appreciated across a broad spectrum of accepted works.\n",
        "\n",
        "Finally, this project served as a way to explore how meaningful knowledge can be extracted from data and how such insights can be leveraged for further analytical methods. While not a complete or exhaustive study, it already touches on several interesting themes, from keyword-based analysis to sentiment interpretation and demonstrates how even limited data, when well-analyzed, can offer valuable understanding.\\\n",
        "Given the time constraints and the limited knowledge on the use of modern machine learning models, the work provides a nice foundation and allows for further investigations."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "003fdc9c912f4efebd0b24d9b5584017": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1994b3246d0c4e2c96bbf579ac0b2add",
              "IPY_MODEL_06ef576ba5054d9faaf64cf5564b89f2",
              "IPY_MODEL_ceaed24ce67d4aec857ccaa14c354a56"
            ],
            "layout": "IPY_MODEL_c4d7104dfab14dbb9a3884af87f80df9"
          }
        },
        "00dd5b7a42da4121bfa7cb546e06a3af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02d1162d680d4243b113cb19a53513b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0308b0d5630b44f1bba7c1aa5b18d27d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed0ebc04fe2247639ecc28e8f7638240",
            "placeholder": "",
            "style": "IPY_MODEL_31e06cdf02a1462cae86557665c1c690",
            "value": "1.36M/1.36M[00:00&lt;00:00,13.2MB/s]"
          }
        },
        "044f63def03a47ce9e278d9f72a70abb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "064d556f5f30494482e7240d5e4deacd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06ef576ba5054d9faaf64cf5564b89f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a66b684891d4fd5a415a9dcb1e5c81a",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80a5a93288ed4c2e84ce3763e714a8bc",
            "value": 231508
          }
        },
        "07582508632b43b79f4d1e4d8188e605": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08ad0293b15045e1a6dfc48947ed1e22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0912b906478d4e1da834d6d659988b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6812dcf6697643239f77176d99cfdfcb",
            "placeholder": "",
            "style": "IPY_MODEL_08ad0293b15045e1a6dfc48947ed1e22",
            "value": "config.json:100%"
          }
        },
        "0d28e5778bfc44a0a8752af881721c42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "116bf0c85aec4b6387b45e2645094005": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82e497986e294f2383be37bd531d3313",
            "placeholder": "",
            "style": "IPY_MODEL_ed596d09a8ac40dd90574837348c5c14",
            "value": "899k/899k[00:00&lt;00:00,26.0MB/s]"
          }
        },
        "142d99c05fab474fb6bc865c60b4e386": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "168a0c4cf5244bacab7c6fba9bb19568": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1994b3246d0c4e2c96bbf579ac0b2add": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4c0b4bd04db4c10a7a1d6648bcb04b6",
            "placeholder": "",
            "style": "IPY_MODEL_8f3cd8234ac946679e13d001ec6d13c1",
            "value": "vocab.txt:100%"
          }
        },
        "1f91172173fa4cf99fbb179c133abdc9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f95dacabc414109918d7ca6745fad05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "273c0dfeb3ed4343ac634207ca574ae7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fa7e7ab743c4fcba8cd3fef36be6fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_142d99c05fab474fb6bc865c60b4e386",
            "placeholder": "",
            "style": "IPY_MODEL_84da9ab8fb8e499992a3620513ea331a",
            "value": "model.safetensors:100%"
          }
        },
        "31e06cdf02a1462cae86557665c1c690": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "330e09be8a9643c5a2f62a2e1d273234": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34d81d340e5443f09b66cad39733fe03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "362c0fa9d7c048c7a4ed09bc7ab72023": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_704efced50754c5d9b9d33253ad98647",
            "placeholder": "",
            "style": "IPY_MODEL_880cc986e20544f3bb3f3e59d409dfec",
            "value": "config.json:100%"
          }
        },
        "3a48d8f6d34f458bb553cfe91e14fad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4287012071604f0989f50bc0020cf4b3",
            "placeholder": "",
            "style": "IPY_MODEL_b322054572c84ac185348d574711acdb",
            "value": "vocab.json:100%"
          }
        },
        "3b8b2138c30240b5959f4ddec66ecd0f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3db15f8b64044899afc366d9e2522be6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40eef96ef8d042898ae0ab178a0c2942": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41ce98f916cb430da77906e3d3392acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "423fb8d60a8b4de3bc2aeeb986ada6af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_330e09be8a9643c5a2f62a2e1d273234",
            "placeholder": "",
            "style": "IPY_MODEL_88d0776599ef4f2ca791aa58ce005411",
            "value": "268M/268M[00:02&lt;00:00,126MB/s]"
          }
        },
        "4283422cbb4c44fc8a4f57152826f746": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4287012071604f0989f50bc0020cf4b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4acdc37965ad4208b39c206bc664caad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b2e9476e2354d629b1bf648687d755e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3df620db49046928eafe37dcedc6b2b",
              "IPY_MODEL_7cee3f68394f4dfaa8e3e8935e628dd5",
              "IPY_MODEL_e82029be99024e439145999dc7aad2dc"
            ],
            "layout": "IPY_MODEL_c8fe3cfb959a48ebace22003307c6416"
          }
        },
        "4b63ed0b22dc4b18ad1fb75c8c0241b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50b9de15b2c24d89a41d93fc7fbed2ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "521f564ec40d4f1db181a0d73f3bf600": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4acdc37965ad4208b39c206bc664caad",
            "placeholder": "",
            "style": "IPY_MODEL_0d28e5778bfc44a0a8752af881721c42",
            "value": "629/629[00:00&lt;00:00,25.8kB/s]"
          }
        },
        "555aa23347644d60969a4728c5ed71e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0912b906478d4e1da834d6d659988b77",
              "IPY_MODEL_d568c49eec354a3da65b5068a7f2f938",
              "IPY_MODEL_60e39c038a1d4737b8b80aea3560d35d"
            ],
            "layout": "IPY_MODEL_4b63ed0b22dc4b18ad1fb75c8c0241b2"
          }
        },
        "5656af2ca4c3427b805e34ec7b2d756e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfec6489bc3a44d48ccd02df4d1d3390",
              "IPY_MODEL_cabd191380774056a9b4704035a0ec38",
              "IPY_MODEL_e7ebe848567940f3a47a04858eda28dd"
            ],
            "layout": "IPY_MODEL_4283422cbb4c44fc8a4f57152826f746"
          }
        },
        "5661ac17164d45c0b96ba6981e2fdea2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d3d8cc0bf614d79a261b5e5f32af8aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_886ee833e48a4885b38c4777f8937d07",
            "placeholder": "",
            "style": "IPY_MODEL_c5323def2c7b4b7683e6cac57a926b0e",
            "value": "1.63G/1.63G[00:16&lt;00:00,155MB/s]"
          }
        },
        "5e5c7fecb10547669ddc9045680a9c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60e39c038a1d4737b8b80aea3560d35d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2d1889f912445eb9cf987ea4701dc63",
            "placeholder": "",
            "style": "IPY_MODEL_bfff50ef15df4d588c43123e763dcbcd",
            "value": "1.58k/1.58k[00:00&lt;00:00,65.6kB/s]"
          }
        },
        "612d211aeaaf405caaa757cc333e2b3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "648918d608d04f0ba6dac8858530eabe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "651d92d97521431a94fae57ba4de0587": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6543de4451cd42aa8186725e7fc936ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "656e989e37c54ea09713f6ff88a47520": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6812dcf6697643239f77176d99cfdfcb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "690420dfa1524c0a846d358f5e0eef76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fbf41f0a7de42fd85cf2265d99ad609",
              "IPY_MODEL_b976a02a7e9442238df2e28d2c4d210d",
              "IPY_MODEL_5d3d8cc0bf614d79a261b5e5f32af8aa"
            ],
            "layout": "IPY_MODEL_72f0a8f2fff94671a621fda7250959ee"
          }
        },
        "6920e2f7c0fd4b9693fa079d35134f05": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a49a3dd0eb34cfe884653f106052920": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8002d77f34864ab6a41bf19188f0e63b",
              "IPY_MODEL_a066fb9fc01044628cfee5d88e75c667",
              "IPY_MODEL_8f322e07a1f4405c86baeac9dc9724cf"
            ],
            "layout": "IPY_MODEL_648918d608d04f0ba6dac8858530eabe"
          }
        },
        "6a66b684891d4fd5a415a9dcb1e5c81a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c1e83138b0548d08538fb37639135b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fbf41f0a7de42fd85cf2265d99ad609": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90e63c7e744047708de213adee53e234",
            "placeholder": "",
            "style": "IPY_MODEL_ce679017510c4d9890b9b1c7ce2e341b",
            "value": "model.safetensors:100%"
          }
        },
        "704efced50754c5d9b9d33253ad98647": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72f0a8f2fff94671a621fda7250959ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cee3f68394f4dfaa8e3e8935e628dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c190424dda2349ab8550586fcbd0ae6d",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34d81d340e5443f09b66cad39733fe03",
            "value": 456318
          }
        },
        "8002d77f34864ab6a41bf19188f0e63b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b8b2138c30240b5959f4ddec66ecd0f",
            "placeholder": "",
            "style": "IPY_MODEL_1f95dacabc414109918d7ca6745fad05",
            "value": "generation_config.json:100%"
          }
        },
        "80a5a93288ed4c2e84ce3763e714a8bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81b658fb4f69466ebbe9215b85b4666c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9331b2394dd4cbfbc02ba8f1eab0ce9",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_656e989e37c54ea09713f6ff88a47520",
            "value": 1355863
          }
        },
        "82e497986e294f2383be37bd531d3313": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84da9ab8fb8e499992a3620513ea331a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "870e8abcf1314a0e957c2e8a0544c716": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "880cc986e20544f3bb3f3e59d409dfec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "886ee833e48a4885b38c4777f8937d07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88d0776599ef4f2ca791aa58ce005411": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89e61b9d77094bcea0883f88a2063198": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da840982fbdb4df1ae67fc4bade0f598",
            "max": 629,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_faf31c079431450ea07d48ca8eb7457e",
            "value": 629
          }
        },
        "8cd7847f2180479ca924203689de1303": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2fa7e7ab743c4fcba8cd3fef36be6fc0",
              "IPY_MODEL_a91e3bbe7f734213ac864509c3506249",
              "IPY_MODEL_423fb8d60a8b4de3bc2aeeb986ada6af"
            ],
            "layout": "IPY_MODEL_168a0c4cf5244bacab7c6fba9bb19568"
          }
        },
        "8f322e07a1f4405c86baeac9dc9724cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_951ec7c1447f49a1a900056361b3a9c8",
            "placeholder": "",
            "style": "IPY_MODEL_6c1e83138b0548d08538fb37639135b4",
            "value": "363/363[00:00&lt;00:00,22.3kB/s]"
          }
        },
        "8f3cd8234ac946679e13d001ec6d13c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90e63c7e744047708de213adee53e234": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "951ec7c1447f49a1a900056361b3a9c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a066fb9fc01044628cfee5d88e75c667": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6543de4451cd42aa8186725e7fc936ff",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_651d92d97521431a94fae57ba4de0587",
            "value": 363
          }
        },
        "a628300859eb4c058b355572426706f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_064d556f5f30494482e7240d5e4deacd",
            "placeholder": "",
            "style": "IPY_MODEL_612d211aeaaf405caaa757cc333e2b3c",
            "value": "tokenizer.json:100%"
          }
        },
        "a91e3bbe7f734213ac864509c3506249": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00dd5b7a42da4121bfa7cb546e06a3af",
            "max": 267832558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_044f63def03a47ce9e278d9f72a70abb",
            "value": 267832558
          }
        },
        "a9331b2394dd4cbfbc02ba8f1eab0ce9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a951723e985a4c3e88820cb182a0a3ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad46cc46330747f6af273ab9ebb78d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a628300859eb4c058b355572426706f5",
              "IPY_MODEL_81b658fb4f69466ebbe9215b85b4666c",
              "IPY_MODEL_0308b0d5630b44f1bba7c1aa5b18d27d"
            ],
            "layout": "IPY_MODEL_a951723e985a4c3e88820cb182a0a3ce"
          }
        },
        "b322054572c84ac185348d574711acdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b976a02a7e9442238df2e28d2c4d210d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5540f8d756c4bb18c86997e64baaf83",
            "max": 1625222120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50b9de15b2c24d89a41d93fc7fbed2ba",
            "value": 1625222120
          }
        },
        "bfff50ef15df4d588c43123e763dcbcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c190424dda2349ab8550586fcbd0ae6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4c0b4bd04db4c10a7a1d6648bcb04b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4d7104dfab14dbb9a3884af87f80df9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5323def2c7b4b7683e6cac57a926b0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5540f8d756c4bb18c86997e64baaf83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8fe3cfb959a48ebace22003307c6416": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca17b9a7c658421fafe7eacf146ac542": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cabd191380774056a9b4704035a0ec38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40eef96ef8d042898ae0ab178a0c2942",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1ad9cb9e601490ebd9e83adb96e21b4",
            "value": 48
          }
        },
        "ce679017510c4d9890b9b1c7ce2e341b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ceaed24ce67d4aec857ccaa14c354a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5661ac17164d45c0b96ba6981e2fdea2",
            "placeholder": "",
            "style": "IPY_MODEL_02d1162d680d4243b113cb19a53513b9",
            "value": "232k/232k[00:00&lt;00:00,3.59MB/s]"
          }
        },
        "cfec6489bc3a44d48ccd02df4d1d3390": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6ece860fff54ecaacc17e8835d1a6c6",
            "placeholder": "",
            "style": "IPY_MODEL_5e5c7fecb10547669ddc9045680a9c82",
            "value": "tokenizer_config.json:100%"
          }
        },
        "d2d1889f912445eb9cf987ea4701dc63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3df620db49046928eafe37dcedc6b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6920e2f7c0fd4b9693fa079d35134f05",
            "placeholder": "",
            "style": "IPY_MODEL_da0b586decdf48b5ab170af3f13126ed",
            "value": "merges.txt:100%"
          }
        },
        "d568c49eec354a3da65b5068a7f2f938": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f556bd0d8457459a8e9ca3ebf16734ab",
            "max": 1585,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc91642f4584439e8d16ac3bf8e296cb",
            "value": 1585
          }
        },
        "d92de0301331439aa8a754cac17f8231": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_362c0fa9d7c048c7a4ed09bc7ab72023",
              "IPY_MODEL_89e61b9d77094bcea0883f88a2063198",
              "IPY_MODEL_521f564ec40d4f1db181a0d73f3bf600"
            ],
            "layout": "IPY_MODEL_273c0dfeb3ed4343ac634207ca574ae7"
          }
        },
        "da0b586decdf48b5ab170af3f13126ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da3107d259ca4fbc82d0b16bc5a50391": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca17b9a7c658421fafe7eacf146ac542",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07582508632b43b79f4d1e4d8188e605",
            "value": 898823
          }
        },
        "da840982fbdb4df1ae67fc4bade0f598": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc91642f4584439e8d16ac3bf8e296cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de44a06a324445fea14cecc0a3b3a5a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a48d8f6d34f458bb553cfe91e14fad2",
              "IPY_MODEL_da3107d259ca4fbc82d0b16bc5a50391",
              "IPY_MODEL_116bf0c85aec4b6387b45e2645094005"
            ],
            "layout": "IPY_MODEL_870e8abcf1314a0e957c2e8a0544c716"
          }
        },
        "e1ad9cb9e601490ebd9e83adb96e21b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6ece860fff54ecaacc17e8835d1a6c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7ebe848567940f3a47a04858eda28dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f91172173fa4cf99fbb179c133abdc9",
            "placeholder": "",
            "style": "IPY_MODEL_e9de5201452a4e55b5ee6c21fa1e4084",
            "value": "48.0/48.0[00:00&lt;00:00,3.40kB/s]"
          }
        },
        "e82029be99024e439145999dc7aad2dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3db15f8b64044899afc366d9e2522be6",
            "placeholder": "",
            "style": "IPY_MODEL_41ce98f916cb430da77906e3d3392acf",
            "value": "456k/456k[00:00&lt;00:00,8.71MB/s]"
          }
        },
        "e9de5201452a4e55b5ee6c21fa1e4084": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed0ebc04fe2247639ecc28e8f7638240": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed596d09a8ac40dd90574837348c5c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f556bd0d8457459a8e9ca3ebf16734ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faf31c079431450ea07d48ca8eb7457e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
